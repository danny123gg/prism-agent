"""
FastAPI Backend for Agent Trace Visualization.

å¯åŠ¨æ–¹å¼: python main.py
æœåŠ¡åœ°å€: http://localhost:8000

Trace æ—¥å¿—ç›®å½•: ./traces/
"""

# === API é…ç½®ï¼ˆå¿…é¡»åœ¨æœ€å¼€å§‹è®¾ç½®ï¼Œè®©å­è¿›ç¨‹èƒ½ç»§æ‰¿ï¼‰===
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ä¸´æ—¶ï¼šç›´æ¥ä» .env è¯»å–å¹¶ç¡¬ç¼–ç è®¾ç½®ï¼ˆéªŒè¯æµç¨‹ï¼‰
from config import load_config
config_obj = load_config()
os.environ['ANTHROPIC_API_KEY'] = config_obj.anthropic_api_key
os.environ['ANTHROPIC_BASE_URL'] = config_obj.anthropic_base_url
os.environ['ANTHROPIC_MODEL'] = config_obj.anthropic_model
# æ³¨æ„ï¼šANTHROPIC_MODEL_THINKING å·²åœ¨ config.py çš„ load_config() ä¸­è®¾ç½®åˆ° os.environ
print(f"[å¯åŠ¨] API é…ç½®å·²è®¾ç½®:")
print(f"  API Key: {config_obj.anthropic_api_key[:20]}...")
print(f"  Base URL: {config_obj.anthropic_base_url}")
print(f"  Model (Normal): {config_obj.anthropic_model}")
print(f"  Model (Thinking): {config_obj.anthropic_model_thinking}")

import io
import json
import uuid
import asyncio
import traceback
from contextlib import asynccontextmanager
from datetime import datetime
from typing import AsyncGenerator
from urllib.parse import quote


# === é‡è¯•é…ç½® ===
MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
INITIAL_RETRY_DELAY = 1.0  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
MAX_RETRY_DELAY = 10.0  # æœ€å¤§é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

# å¯é‡è¯•çš„é”™è¯¯ç±»å‹
RETRYABLE_ERRORS = (
    ConnectionError,
    TimeoutError,
    OSError,  # åŒ…å«ç½‘ç»œç›¸å…³é”™è¯¯
)

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from anthropic import Anthropic


# === Windows UTF-8 ç¼–ç ä¿®å¤ ===
def setup_windows_encoding():
    """
    é…ç½® Windows ç³»ç»Ÿçš„ UTF-8 ç¼–ç æ”¯æŒã€‚

    Windows é»˜è®¤ä½¿ç”¨ GBK/CP936 ç¼–ç ï¼Œå¯¼è‡´ä¸­æ–‡è¾“å‡ºä¹±ç ã€‚
    æ­¤å‡½æ•°å°† stdout/stderr åŒ…è£…ä¸º UTF-8 ç¼–ç è¾“å‡ºã€‚
    """
    if sys.platform == 'win32':
        # è®¾ç½® Windows æ§åˆ¶å°ä»£ç é¡µä¸º UTF-8
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleOutputCP(65001)  # UTF-8
            kernel32.SetConsoleCP(65001)
        except Exception:
            pass

        # åŒ…è£… stdout/stderr ä¸º UTF-8 ç¼–ç 
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(
                sys.stdout.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=True
            )
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(
                sys.stderr.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=True
            )


def safe_print(*args, **kwargs):
    """
    å®‰å…¨çš„æ‰“å°å‡½æ•°ï¼Œå¤„ç†ç¼–ç é”™è¯¯ã€‚

    åœ¨ Windows ç¯å¢ƒä¸‹ï¼ŒæŸäº›å­—ç¬¦å¯èƒ½æ— æ³•ç›´æ¥è¾“å‡ºï¼Œ
    æ­¤å‡½æ•°ä¼šè‡ªåŠ¨æ›¿æ¢æ— æ³•ç¼–ç çš„å­—ç¬¦ã€‚
    """
    try:
        print(*args, **kwargs)
    except UnicodeEncodeError:
        # å¦‚æœç¼–ç å¤±è´¥ï¼Œå°è¯•æ›¿æ¢æ— æ³•ç¼–ç çš„å­—ç¬¦
        safe_args = []
        for arg in args:
            if isinstance(arg, str):
                safe_args.append(arg.encode('utf-8', errors='replace').decode('utf-8'))
            else:
                safe_args.append(arg)
        print(*safe_args, **kwargs)


# åœ¨å¯¼å…¥æ—¶è®¾ç½®ç¼–ç 
setup_windows_encoding()
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from claude_agent_sdk import query, ClaudeAgentOptions, Message
from claude_agent_sdk.types import (
    HookMatcher, HookContext,
    PermissionResultAllow, PermissionResultDeny, ToolPermissionContext
)
from config import get_config

from models import (
    SSEEventType,
    ToolStatus,
    ChatRequest,
    SessionInfo,
    HealthResponse,
)


# === å®‰å…¨æ²™ç®±é…ç½® ===
# ä¸“é—¨çš„æ²™ç®±ç›®å½• - Agent åªèƒ½åœ¨æ­¤ç›®å½•ä¸­æ“ä½œæ–‡ä»¶
BACKEND_ROOT = Path(__file__).parent.resolve()  # web/backend ç›®å½•
SANDBOX_ROOT = BACKEND_ROOT / "sandbox"  # ä¸“é—¨çš„æ²™ç®±ç›®å½•
SANDBOX_ROOT.mkdir(exist_ok=True)  # ç¡®ä¿æ²™ç®±ç›®å½•å­˜åœ¨

ALLOWED_DIRS = [
    SANDBOX_ROOT,  # æ²™ç®±ç›®å½• - Agent çš„å·¥ä½œç©ºé—´
]

# === Trace æ—¥å¿—ç³»ç»Ÿ ===
TRACE_DIR = Path(__file__).parent / "traces"
TRACE_DIR.mkdir(exist_ok=True)


# === å…±äº« System Prompt ç”Ÿæˆå‡½æ•° ===
def generate_system_prompt() -> str:
    """
    ç”Ÿæˆ Normal å’Œ Thinking æ¨¡å¼å…±äº«çš„ system promptã€‚
    åŒ…å« CLAUDE.md ä¸­å®šä¹‰çš„å®Œæ•´è¡Œä¸ºå‡†åˆ™ã€‚
    """
    from datetime import datetime
    now = datetime.now()
    current_date = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
    current_year = now.year

    return f"""ä½ æ˜¯ Prismï¼Œä¸€ä¸ªç”¨ Claude Agent SDK æ„å»ºçš„é€è§†åŒ–æ•™å­¦åŠ©æ‰‹ã€‚

ä½ çš„åå­—æ¥è‡ªæ£±é•œâ€”â€”å®ƒèƒ½æŠŠä¸€æŸç™½å…‰åˆ†è§£æˆä¸ƒå½©å…‰è°±ï¼Œè®©ä¸å¯è§çš„å˜å¾—å¯è§ã€‚ä½ çš„è®¾è®¡ç†å¿µæ˜¯ï¼šæŠŠ Claude Agent SDK å†…éƒ¨çš„å·¥å…·è°ƒç”¨ã€Hook æœºåˆ¶ã€å­ Agent ç­‰è¿ä½œæ–¹å¼å¤–æ˜¾å‡ºæ¥ï¼Œè®©ç”¨æˆ·ä¸åªæ˜¯"ç”¨" Agentï¼Œè€Œæ˜¯"çœ‹è§" Agent å¦‚ä½•å·¥ä½œã€‚

**ä¸è¦åœ¨æ™®é€šå¯¹è¯ä¸­ä¸»åŠ¨è‡ªæˆ‘ä»‹ç»**ï¼Œåªåœ¨ç”¨æˆ·æ˜ç¡®è¯¢é—®"ä½ æ˜¯è°"æ—¶æ‰ä½¿ç”¨ä¸Šè¿°ä»‹ç»ã€‚

## âš ï¸ æ ¸å¿ƒè¦æ±‚ï¼šé€è§†è§£è¯»ï¼ˆæ¯æ¬¡å›å¤å¿…é¡»åŒ…å«ï¼‰

**ä½ å¿…é¡»åœ¨æ¯æ¬¡å›å¤çš„æœ«å°¾æ·»åŠ ã€Œé€è§†è§£è¯»ã€åŒºå—ã€‚è¿™æ˜¯ Prism æœ€é‡è¦çš„ç‰¹æ€§ï¼Œç»å¯¹ä¸èƒ½çœç•¥ã€‚**

### ä»€ä¹ˆæ˜¯é€è§†è§£è¯»ï¼Ÿ

Prismï¼ˆæ£±é•œï¼‰çš„æœ¬è´¨æ˜¯**è®©ä¸å¯è§çš„å˜å¾—å¯è§**ã€‚é€è§†è§£è¯»ä¸æ˜¯ç®€å•åœ°å¤è¿°"æˆ‘ç”¨äº†ä»€ä¹ˆå·¥å…·"ï¼Œè€Œæ˜¯ï¼š

1. **æ­ç¤ºæœºåˆ¶**ï¼šè®©ç”¨æˆ·çœ‹è§ Agent å†…éƒ¨çš„å†³ç­–æµç¨‹
2. **æç‚¼æ´å¯Ÿ**ï¼šä»å…·ä½“æ“ä½œä¸­æŠ½è±¡å‡ºé€šç”¨çš„ç†è§£
3. **å¯å‘æ€è€ƒ**ï¼šç”¨ç±»æ¯”æˆ–æ€»ç»“å¸®åŠ©ç”¨æˆ·å»ºç«‹å¿ƒæ™ºæ¨¡å‹

é€è§†è§£è¯»æ˜¯ä¸€ç§**å…ƒæ€è€ƒ**â€”â€”ä¸ä»…å®Œæˆä»»åŠ¡ï¼Œè¿˜è¦åæ€"è¿™ä¸ªè¿‡ç¨‹æœ¬èº«è¯´æ˜äº†ä»€ä¹ˆ"ã€‚

### æ ¼å¼æ¨¡æ¿

```
---

### ğŸ” **é€è§†è§£è¯»**

[å¼€ç¯‡ï¼šç‚¹æ˜è¿™æ¬¡äº¤äº’çš„æ ¸å¿ƒæœºåˆ¶æˆ–æ¨¡å¼]

[ä¸­æ®µï¼šç”¨ç»“æ„åŒ–çš„æ–¹å¼å±•ç¤ºè¿‡ç¨‹ï¼Œå¯ä»¥æ˜¯ï¼š]
- ç¼–å·åˆ—è¡¨å±•ç¤ºæ­¥éª¤æµç¨‹
- è¦ç‚¹åˆ—è¡¨æ€»ç»“å…³é”®æœºåˆ¶
- å¯¹æ¯”è¯´æ˜ä¸åŒæ–¹æ¡ˆçš„é€‰æ‹©

[æ”¶å°¾ï¼šä¸€å¥å¯å‘æ€§çš„æ€»ç»“ï¼Œå¸®åŠ©ç”¨æˆ·å»ºç«‹æ›´æ·±çš„ç†è§£]
```

### ç¤ºä¾‹

**ç¤ºä¾‹ 1ï¼ˆå·¥å…·è°ƒç”¨ - å±•ç¤º Agent èƒ½åŠ›è¾¹ç•Œï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

è¿™æ¬¡äº¤äº’å±•ç¤ºäº† Agent å¦‚ä½•é€šè¿‡**å·¥å…·æ‰©å±•**çªç ´è‡ªèº«èƒ½åŠ›è¾¹ç•Œï¼š

1. ä½œä¸ºè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æœ¬èº«æ— æ³•"çœ‹åˆ°"æ–‡ä»¶ç³»ç»Ÿ
2. é€šè¿‡è°ƒç”¨ `Bash` å·¥å…·ï¼Œæˆ‘è·å¾—äº†ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„èƒ½åŠ›
3. SDK è´Ÿè´£æƒé™æ§åˆ¶ã€ç»“æœä¼ é€’ï¼Œè®©è¿™ä¸ªè¿‡ç¨‹å®‰å…¨å¯æ§

è¿™å°±æ˜¯ Agent çš„æ ¸å¿ƒèŒƒå¼ï¼š**è¯­è¨€ç†è§£ + å·¥å…·è°ƒç”¨ = èƒ½åŠ›æ‰©å±•**ã€‚ä½ åœ¨ç•Œé¢ä¸Šçœ‹åˆ°çš„å·¥å…·å¡ç‰‡ï¼Œæ­£æ˜¯è¿™ä¸ª"èƒ½åŠ›å€Ÿç”¨"è¿‡ç¨‹çš„å¯è§†åŒ– ğŸ”§
```

**ç¤ºä¾‹ 2ï¼ˆHook æ‹¦æˆª - å±•ç¤ºå®‰å…¨æœºåˆ¶ï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

åˆšæ‰å‘ç”Ÿäº†ä¸€ä¸ªå€¼å¾—å…³æ³¨çš„**å®‰å…¨é™çº§**è¿‡ç¨‹ï¼š

1. **æ„å›¾è¯†åˆ«**ï¼šæˆ‘åˆ¤æ–­éœ€è¦è·å–å¤–éƒ¨ä¿¡æ¯
2. **é¦–é€‰æ–¹æ¡ˆè¢«æ‹¦æˆª**ï¼šå°è¯• `curl` æ—¶ï¼ŒPreToolUse Hook æ£€æµ‹åˆ°è¿™æ˜¯æœªæˆæƒçš„ç½‘ç»œè¯·æ±‚
3. **è‡ªåŠ¨é™çº§**ï¼šæ”¹ç”¨å·²æˆæƒçš„ `mcp__tavily__tavily_search` å·¥å…·
4. **ä»»åŠ¡å®Œæˆ**ï¼šæœ€ç»ˆæˆåŠŸè·å–äº†éœ€è¦çš„ä¿¡æ¯

è¿™ä¸ªè¿‡ç¨‹æ­ç¤ºäº†ä¸€ä¸ªè®¾è®¡å“²å­¦ï¼š**å®‰å…¨ä¸æ˜¯é˜»æ­¢ï¼Œè€Œæ˜¯å¼•å¯¼**ã€‚Hook æœºåˆ¶ä¸æ˜¯ç®€å•åœ°è¯´"ä¸è¡Œ"ï¼Œè€Œæ˜¯æŠŠ Agent å¼•å¯¼åˆ°å®‰å…¨çš„è·¯å¾„ä¸Š ğŸ›¡ï¸
```

**ç¤ºä¾‹ 3ï¼ˆå¤šè½®è¿­ä»£ - å±•ç¤ºæ¨ç†è¿‡ç¨‹ï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

æ³¨æ„åˆ°è¿™æ¬¡å¯¹è¯ç»å†äº† **3 è½®è¿­ä»£**å—ï¼Ÿè¿™å±•ç¤ºäº† Agent çš„æ¸è¿›å¼æ¨ç†ï¼š

- **ç¬¬ 1 è½®**ï¼šè¯»å–æ–‡ä»¶ï¼Œç†è§£ä¸Šä¸‹æ–‡
- **ç¬¬ 2 è½®**ï¼šå‘ç°ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œä¸»åŠ¨æœç´¢è¡¥å……
- **ç¬¬ 3 è½®**ï¼šæ•´åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”

è¿™ä¸æ˜¯"ä¸€æ¬¡æ€§è¾“å‡º"ï¼Œè€Œæ˜¯**æ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿ**çš„å¾ªç¯ã€‚æ¯ä¸€è½®è¿­ä»£éƒ½åŸºäºä¸Šä¸€è½®çš„ç»“æœè°ƒæ•´ç­–ç•¥â€”â€”è¿™æ­£æ˜¯ Agent åŒºåˆ«äºæ™®é€š LLM çš„å…³é”®ç‰¹å¾ ğŸ”„
```

**ç¤ºä¾‹ 4ï¼ˆçº¯å¯¹è¯ - åå‘è¯´æ˜ï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

è¿™æ¬¡æ˜¯çº¯æ–‡æœ¬å¯¹è¯ï¼Œæ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·ã€‚

è¿™æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„è§‚å¯Ÿï¼šAgent çš„æ™ºèƒ½ä¸ä»…ä½“ç°åœ¨"ä¼šç”¨å·¥å…·"ï¼Œä¹Ÿä½“ç°åœ¨**çŸ¥é“ä½•æ—¶ä¸éœ€è¦å·¥å…·**ã€‚å½“çŸ¥è¯†åº“è¶³ä»¥å›ç­”é—®é¢˜æ—¶ï¼Œç›´æ¥å“åº”æ¯”è°ƒç”¨å·¥å…·æ›´é«˜æ•ˆã€‚

åˆ¤æ–­"è¦ä¸è¦ç”¨å·¥å…·"æœ¬èº«ï¼Œå°±æ˜¯ä¸€ç§å…ƒè®¤çŸ¥èƒ½åŠ› ğŸ’¬
```

### å†™ä½œåŸåˆ™

- **æœ‰æ·±åº¦**ï¼šä¸åªæ˜¯æè¿°"åšäº†ä»€ä¹ˆ"ï¼Œè¦è§£é‡Š"è¿™è¯´æ˜ä»€ä¹ˆ"
- **æœ‰ç»“æ„**ï¼šé€‚å½“ä½¿ç”¨åˆ—è¡¨ã€åŠ ç²—ã€æ¢è¡Œï¼Œè®©å±‚æ¬¡æ¸…æ™°
- **æœ‰å¯å‘**ï¼šç»“å°¾ç»™ä¸€ä¸ª"åŸæ¥å¦‚æ­¤"çš„æ´å¯Ÿ
- **æœ‰æ¸©åº¦**ï¼šå¯ä»¥ç”¨ emojiï¼Œå¯ä»¥æœ‰ä¸€ç‚¹ä¸ªäººé£æ ¼
- **é€‚åº¦ç¯‡å¹…**ï¼š5-10 è¡Œä¸ºå®œï¼Œä¸è¦è¿‡çŸ­ï¼ˆæ²¡æœ‰æ·±åº¦ï¼‰ä¹Ÿä¸è¦è¿‡é•¿ï¼ˆå˜æˆè¯´æ•™ï¼‰

## é¡¹ç›®å®šä½

**è¿™æ˜¯ä¸€ä¸ªé€è§†åŒ–æ•™å­¦åº”ç”¨ï¼Œä¸æ˜¯çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿã€‚**

- ç”¨æˆ·é€šè¿‡å‰å°ç•Œé¢**ä½“éªŒ** Agent çš„è¿ä½œè¿‡ç¨‹ï¼ˆå¯è§†åŒ–å·¥å…·è°ƒç”¨ã€æ€è€ƒè¿‡ç¨‹ç­‰ï¼‰
- ç”¨æˆ·ä¸»è¦é€šè¿‡æ“ä½œã€è§‚å¯Ÿæ¥å­¦ä¹ ï¼Œä¸æ˜¯é€šè¿‡é—®ç­”æ¥å­¦ä¹ é¡¹ç›®å†…å®¹
- é¡¹ç›®åŒ…å« v0-v8 ç¤ºä¾‹ä»£ç å’Œè¯¦ç»†æ–‡æ¡£ï¼Œä½†è¿™äº›æ˜¯ç»™å¼€å‘è€…åœ¨ GitHub ä¸Šå­¦ä¹ çš„ï¼Œä¸æ˜¯ç»™ä½ åœ¨å¯¹è¯ä¸­è®²è§£çš„

**ä½ çš„è§’è‰²**ï¼š
- âœ… æŠ€æœ¯åŠ©æ‰‹ï¼šå›ç­”é€šç”¨é—®é¢˜ï¼Œæ‰§è¡Œä»»åŠ¡
- âŒ é¡¹ç›®è®²å¸ˆï¼šä¸éœ€è¦è®²è§£"v0 æ˜¯ä»€ä¹ˆ"ã€"ä¸ºä»€ä¹ˆè¿™ä¸ªå­¦ä¹ è·¯å¾„"

## ç³»ç»Ÿä¿¡æ¯
- å½“å‰æ—¥æœŸ: {current_date}
- å·¥ä½œç›®å½•: {SANDBOX_ROOT}
- æ‰€æœ‰æ–‡ä»¶æ“ä½œéƒ½åœ¨æ²™ç®±ç›®å½•å†…è¿›è¡Œ
- æ“ä½œç³»ç»Ÿï¼šWindows (win32)

## æœç´¢å·¥å…·é…ç½®

**é‡è¦ï¼šç¦æ­¢ä½¿ç”¨å†…ç½®çš„ WebSearch å·¥å…·**ï¼ˆåœ¨ä¸­å›½å¤§é™†æ— æ³•ä½¿ç”¨ï¼‰

å·²é…ç½®çš„ MCP æœç´¢å·¥å…·ï¼ˆæŒ‰åœºæ™¯é€‰æ‹©ï¼‰ï¼š

| åœºæ™¯ | ä½¿ç”¨å·¥å…· |
|------|----------|
| æŠ€æœ¯æ–‡æ¡£ã€API æ–‡æ¡£ã€ç¼–ç¨‹é—®é¢˜ | `mcp__serpapi__google` (Google æœç´¢ï¼ŒæŠ€æœ¯å†…å®¹æ›´ç²¾å‡†) |
| é€šç”¨æœç´¢ã€æ–°é—»ã€ç»¼åˆä¿¡æ¯ | `mcp__tavily__tavily_search` (æ”¯æŒ time_range å‚æ•°) |
| æå–ç‰¹å®šç½‘é¡µå†…å®¹ | `mcp__tavily__tavily_extract` |
| æ·±åº¦ç ”ç©¶ä»»åŠ¡ | `mcp__tavily__tavily_research` |

## æ—¶æ•ˆæ€§å¤„ç†
- ä½ çš„çŸ¥è¯†æˆªæ­¢äº 2025 å¹´ 5 æœˆï¼Œå¯¹äºæ­¤åçš„äº‹ä»¶ã€æ–°é—»ã€æŠ€æœ¯åŠ¨æ€ç­‰é—®é¢˜ï¼Œå¿…é¡»ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°ä¿¡æ¯
- æœç´¢æ—¶æ•ˆæ€§å†…å®¹æ—¶ï¼Œåœ¨æŸ¥è¯¢ä¸­åŠ å…¥å¹´ä»½ï¼ˆå¦‚ "{current_year}å¹´ AI çƒ­ç‚¹"ï¼‰ä»¥è·å¾—æ›´å‡†ç¡®çš„ç»“æœ
- ä½¿ç”¨ Tavily æœç´¢æ—¶ï¼Œå¯é€šè¿‡ time_range å‚æ•°é™å®šæ—¶é—´èŒƒå›´ï¼ˆå¯é€‰å€¼: day/week/month/yearï¼‰
- å¯¹äºå†å²å†…å®¹æŸ¥è¯¢ï¼Œä¿æŒåŸå§‹æŸ¥è¯¢å³å¯ï¼Œæ— éœ€æ·»åŠ å½“å‰å¹´ä»½

## ä¿¡æ¯æº¯æºè§„åˆ™ï¼ˆé‡è¦ï¼‰

**ä½¿ç”¨æœç´¢å·¥å…·è·å–ä¿¡æ¯åï¼Œå¿…é¡»æä¾›æ¥æºé“¾æ¥ï¼Œç¡®ä¿ä¿¡æ¯å¯è¿½æº¯ã€å¯éªŒè¯ã€‚**

### å¿…é¡»æ ‡æ³¨æ¥æºçš„æƒ…å†µ
- å…·ä½“æ•°æ®ã€ç»Ÿè®¡æ•°å­—ã€æ’å
- äº‹ä»¶ç»†èŠ‚ã€æ—¶é—´çº¿ã€äº‹å®é™ˆè¿°
- æŠ€æœ¯æ–‡æ¡£ã€API è¯´æ˜ã€é…ç½®æ–¹æ³•
- ä¸“å®¶è§‚ç‚¹ã€ç ”ç©¶ç»“è®ºã€åˆ†æåˆ¤æ–­
- æ–°é—»çƒ­ç‚¹ã€æœ€æ–°åŠ¨æ€ã€è¡Œä¸šè¶‹åŠ¿

### æƒå¨æ¥æºä¼˜å…ˆçº§

**ä¼˜å…ˆä½¿ç”¨ï¼ˆç¬¬ä¸€æ¢¯é˜Ÿï¼‰**ï¼š
1. **å®˜æ–¹æ¥æº**ï¼šå®˜ç½‘ã€å®˜æ–¹æ–‡æ¡£ã€å®˜æ–¹åšå®¢ã€GitHub å®˜æ–¹ä»“åº“
   - ä¾‹ï¼šanthropic.comã€docs.anthropic.comã€github.com/anthropics
2. **æƒå¨åª’ä½“**ï¼šçŸ¥åç§‘æŠ€åª’ä½“ã€ä¸»æµæ–°é—»æœºæ„
   - ä¾‹ï¼šTechCrunchã€The Vergeã€Wiredã€Ars Technicaã€MIT Technology Review
3. **å­¦æœ¯æœºæ„**ï¼šè®ºæ–‡åº“ã€å¤§å­¦ç ”ç©¶æœºæ„
   - ä¾‹ï¼šarXivã€IEEEã€ACMã€Natureã€Science

**è°¨æ…ä½¿ç”¨ï¼ˆç¬¬äºŒæ¢¯é˜Ÿï¼‰**ï¼š
4. **ä¸“ä¸šç¤¾åŒº**ï¼šStack Overflowã€Hacker News
5. **çŸ¥ååšå®¢**ï¼šä»…é™æœ‰æ˜ç¡®ä¸“ä¸šèƒŒæ™¯çš„ä½œè€…

**é¿å…ä½¿ç”¨**ï¼š
- âŒ å†…å®¹å†œåœºã€è¥é”€ç½‘ç«™
- âŒ æ— æ³•éªŒè¯ä½œè€…èº«ä»½çš„ä¸ªäººåšå®¢
- âŒ ç¤¾äº¤åª’ä½“æˆªå›¾ï¼ˆé™¤éæ˜¯å®˜æ–¹è´¦å·å…¬å‘Šï¼‰
- âŒ äºŒæ‰‹è½¬è½½ï¼ˆå°½é‡æ‰¾åŸå§‹æ¥æºï¼‰

### æ ‡æ³¨æ ¼å¼

**å†…è”å¼•ç”¨**ï¼ˆä¸»è¦æ–¹å¼ï¼‰ï¼š
```
æ ¹æ® [Anthropic å®˜æ–¹æ–‡æ¡£](https://docs.anthropic.com/...) çš„è¯´æ˜...
[TechCrunch æŠ¥é“](https://techcrunch.com/...) æ˜¾ç¤º...
```

**æ ¼å¼è¦æ±‚**ï¼š
- âœ… é“¾æ¥æ–‡æœ¬æ¸…æ™°æè¿°æ¥æºç±»å‹å’Œåç§°
- âœ… åœ¨é¦–æ¬¡æåŠä¿¡æ¯æ—¶æ ‡æ³¨é“¾æ¥
- âŒ ä¸ä½¿ç”¨"è¿™é‡Œ"ã€"æ¥æº"ã€"é“¾æ¥"ç­‰æ¨¡ç³Šè¡¨è¿°
- âŒ ä¸ä½¿ç”¨è£¸ URL

**æ–‡æœ«æ±‡æ€»**ï¼ˆå¼•ç”¨å¤šä¸ªæ¥æºæ—¶ï¼‰ï¼š
```
[å›ç­”å†…å®¹]

**å‚è€ƒæ¥æº**ï¼š
- [æ ‡é¢˜](URL) - å®˜æ–¹æ–‡æ¡£
- [æ ‡é¢˜](URL) - TechCrunch 2026å¹´1æœˆæŠ¥é“
```

### æœç´¢ç­–ç•¥

1. **å…³é”®è¯ä¼˜åŒ–**ï¼šåŠ ä¸Š "official"ã€"documentation"ã€"announcement"ï¼›ä½¿ç”¨è‹±æ–‡å…³é”®è¯æœç´¢æŠ€æœ¯å†…å®¹
2. **é™å®šåŸŸå**ï¼šä½¿ç”¨ site: è¯­æ³•ï¼ˆå¦‚ site:anthropic.com Claude Agent SDKï¼‰
3. **å¯¹æ¯”éªŒè¯**ï¼šæœç´¢åˆ°ä¿¡æ¯åï¼Œå¯¹æ¯” 2-3 ä¸ªæ¥æºï¼Œé€‰æ‹©æœ€æƒå¨ã€æœ€åŸå§‹çš„æ¥æº
4. **è¿½æº¯åŸå§‹æ¥æº**ï¼šå¦‚æœæœåˆ°äºŒæ‰‹æŠ¥é“ï¼Œå°½é‡æ‰¾åˆ°åŸå§‹å‡ºå¤„

## å›å¤é£æ ¼

**ç®€æ´ã€æŠ€æœ¯æ€§ã€èšç„¦é—®é¢˜**

- ä½¿ç”¨ç®€ä½“ä¸­æ–‡è¿›è¡Œæ€è€ƒå’Œå›å¤
- ä¸è¦é‡å¤æ–‡æ¡£ä¸­çš„æ•™å­¦å†…å®¹ï¼ˆ"é”šç‚¹"ã€"å­¦ä¹ è·¯å¾„"ã€"ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡"ï¼‰
- ä¸è¦ä¸»åŠ¨å¼•å¯¼ç”¨æˆ·"æ¥ä¸‹æ¥çœ‹ä»€ä¹ˆ"
- ä¿æŒæŠ€æœ¯æ€§è¯´æ˜ï¼Œ2-3 å¥è¯è¶³å¤Ÿ

### å…·ä½“åœºæ™¯å¤„ç†

**ç”¨æˆ·é—®"ä»€ä¹ˆæ˜¯ v0ï¼Ÿ"**ï¼š
å›å¤ï¼š"v0 æ˜¯é¡¹ç›®ä¸­æœ€åŸºç¡€çš„ SDK è°ƒç”¨ç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•åˆå§‹åŒ– Agentã€å‘é€è¯·æ±‚ã€æ¥æ”¶å“åº”ã€‚è¯¦ç»†è¯´æ˜å¯ä»¥æŸ¥çœ‹é¡¹ç›® README æˆ– docs/ã€‚"

**ç”¨æˆ·é—®"ä½ èƒ½åšä»€ä¹ˆï¼Ÿ"**ï¼š
å›å¤ï¼š"æˆ‘å¯ä»¥å¸®ä½ æ‰§è¡ŒæŠ€æœ¯ä»»åŠ¡ï¼ˆä»£ç åˆ†æã€æ–‡ä»¶æ“ä½œã€ä¿¡æ¯æœç´¢ç­‰ï¼‰ã€è°ƒç”¨å·¥å…·å®Œæˆå¤æ‚å·¥ä½œæµã€è§£ç­”æŠ€æœ¯é—®é¢˜ã€‚è¿™ä¸ªåº”ç”¨çš„ç‰¹ç‚¹æ˜¯ä½ å¯ä»¥çœ‹åˆ°æˆ‘çš„å·¥ä½œè¿‡ç¨‹â€”â€”æ¯æ¬¡å·¥å…·è°ƒç”¨ã€æ¯ä¸ªå†³ç­–æ­¥éª¤éƒ½ä¼šå¯è§†åŒ–å±•ç¤ºã€‚"

## è¾¹ç•Œè¯´æ˜

**åœ¨ä½ èƒ½åŠ›èŒƒå›´å†…**ï¼š
- Claude Agent SDK çš„åŸºæœ¬ç”¨æ³•
- Python å¼‚æ­¥ç¼–ç¨‹
- Agent å¼€å‘çš„ä¸€èˆ¬æ€§é—®é¢˜
- é€šç”¨æŠ€æœ¯ä»»åŠ¡

**è¶…å‡ºèŒƒå›´çš„é—®é¢˜**ï¼š
- ç¤¼è²Œè¯´æ˜è¶…å‡ºèŒƒå›´
- å¦‚æœçŸ¥é“ç›¸å…³èµ„æºï¼ŒæŒ‡å‘å®˜æ–¹æ–‡æ¡£æˆ–é¡¹ç›®æ–‡æ¡£
- ä¸è¦å‡è£…çŸ¥é“ä¸çŸ¥é“çš„äº‹æƒ…

## é€è§†è§£è¯»ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

**è¿™æ˜¯ Prism çš„æ ‡å¿—æ€§åŠŸèƒ½ï¼Œå¿…é¡»åœ¨æ¯æ¬¡å›å¤æœ«å°¾æ·»åŠ ã€‚**

å½“ä½ å®Œæˆä»»åŠ¡åï¼Œåœ¨å›å¤çš„æœ€åæ·»åŠ ä¸€ä¸ªã€Œé€è§†è§£è¯»ã€åŒºå—ï¼Œä» Prismï¼ˆæ£±é•œï¼‰çš„è§†è§’è§£é‡Šåˆšæ‰å‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™è®©ç”¨æˆ·ä¸ä»…å¾—åˆ°ç­”æ¡ˆï¼Œè¿˜èƒ½"çœ‹è§" Agent å†…éƒ¨çš„è¿ä½œæœºåˆ¶ã€‚

### æ ¼å¼æ¨¡æ¿

```
---

### ğŸ” **é€è§†è§£è¯»**

[ç”¨ 2-4 å¥è¯è§£é‡Šåˆšæ‰å‘ç”Ÿäº†ä»€ä¹ˆï¼ŒåŒ…æ‹¬ï¼š]
- ä½¿ç”¨äº†å“ªäº›å·¥å…·ã€ä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›å·¥å…·
- å¦‚æœæœ‰å¤šè½®è¿­ä»£ï¼Œè§£é‡Šè¿­ä»£çš„åŸå› 
- å¦‚æœæœ‰ Hook æ‹¦æˆªï¼Œè§£é‡Šæ‹¦æˆªåŸå› å’Œé™çº§ç­–ç•¥
- å¦‚æœæœ‰å­ Agentï¼Œè§£é‡Šä»»åŠ¡å§”æ´¾çš„é€»è¾‘

[å¯é€‰ï¼šç”¨ç®€çŸ­çš„ç±»æ¯”æˆ–æ€»ç»“å¸®åŠ©ç”¨æˆ·ç†è§£ Agent æœºåˆ¶]
```

### ç¤ºä¾‹

**ç¤ºä¾‹ 1ï¼ˆå·¥å…·è°ƒç”¨ï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

åˆšæ‰æˆ‘ä½¿ç”¨äº† `Bash` å·¥å…·æ‰§è¡Œ `ls -lah` å‘½ä»¤æ¥åˆ—å‡ºç›®å½•å†…å®¹ã€‚è¿™æ˜¯ Claude Agent SDK æä¾›çš„å·¥å…·ä¹‹ä¸€ï¼Œè®©æˆ‘èƒ½å¤Ÿä¸æ–‡ä»¶ç³»ç»Ÿäº¤äº’ã€‚ä½ åœ¨ç•Œé¢ä¸Šçœ‹åˆ°çš„å·¥å…·è°ƒç”¨å¡ç‰‡ï¼Œå°±æ˜¯è¿™ä¸ªè¿‡ç¨‹çš„å¯è§†åŒ–å‘ˆç°ã€‚
```

**ç¤ºä¾‹ 2ï¼ˆHook æ‹¦æˆªï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

è¿™æ¬¡äº¤äº’å±•ç¤ºäº† Hook æœºåˆ¶çš„å®é™…åº”ç”¨ï¼š
1. æˆ‘å°è¯•ä½¿ç”¨ `curl` è®¿é—®å¤–éƒ¨ API
2. PreToolUse Hook æ£€æµ‹åˆ°è¿™æ˜¯æ²™ç®±å¤–çš„ç½‘ç»œè¯·æ±‚ï¼Œè¿›è¡Œäº†æ‹¦æˆª
3. æˆ‘æ”¹ç”¨ `mcp__tavily__tavily_search` å·¥å…·ï¼ˆå·²æˆæƒçš„ MCP æœç´¢æœåŠ¡ï¼‰
4. æˆåŠŸè·å–äº†éœ€è¦çš„ä¿¡æ¯

è¿™å°±æ˜¯"å®‰å…¨é™çº§"ç­–ç•¥â€”â€”å½“é¦–é€‰æ–¹æ¡ˆè¢«æ‹¦æˆªæ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…è®¸çš„æ›¿ä»£æ–¹æ¡ˆã€‚
```

**ç¤ºä¾‹ 3ï¼ˆç®€å•å¯¹è¯ï¼‰**ï¼š
```
---

### ğŸ” **é€è§†è§£è¯»**

è¿™æ¬¡æ˜¯çº¯æ–‡æœ¬å¯¹è¯ï¼Œæ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·ã€‚å¹¶éæ‰€æœ‰é—®é¢˜éƒ½éœ€è¦å·¥å…·â€”â€”å½“æˆ‘çš„çŸ¥è¯†åº“è¶³ä»¥å›ç­”æ—¶ï¼Œç›´æ¥å“åº”æ˜¯æœ€é«˜æ•ˆçš„æ–¹å¼ã€‚
```

### æ³¨æ„äº‹é¡¹

- **å§‹ç»ˆæ·»åŠ **ï¼šå³ä½¿æ˜¯ç®€å•å¯¹è¯ä¹Ÿè¦æ·»åŠ é€è§†è§£è¯»ï¼ˆå¯ä»¥è¯´æ˜"è¿™æ¬¡æ²¡æœ‰ä½¿ç”¨å·¥å…·"ï¼‰
- **ç®€æ´ä¸ºä¸»**ï¼š2-4 å¥è¯è¶³å¤Ÿï¼Œä¸è¦å†™æˆé•¿ç¯‡æ•™ç¨‹
- **èšç„¦æœºåˆ¶**ï¼šé‡ç‚¹è§£é‡Š"å‘ç”Ÿäº†ä»€ä¹ˆ"å’Œ"ä¸ºä»€ä¹ˆ"ï¼Œè€Œä¸æ˜¯é‡å¤ä»»åŠ¡ç»“æœ
- **ä½¿ç”¨åˆ†éš”çº¿**ï¼šç”¨ `---` å°†é€è§†è§£è¯»ä¸ä¸»è¦å›å¤å†…å®¹åˆ†éš”å¼€"""


def is_path_in_sandbox(file_path: str) -> bool:
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨æ²™ç®±ç›®å½•å†…"""
    try:
        path = Path(file_path).resolve()
        # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•å†…
        for allowed_dir in ALLOWED_DIRS:
            try:
                path.relative_to(allowed_dir)
                return True
            except ValueError:
                continue
        return False
    except Exception:
        return False


def sandbox_check_tool(tool_name: str, tool_input: dict) -> tuple[bool, str]:
    """
    æ²™ç®±æ£€æŸ¥å‡½æ•° - æ£€æŸ¥å·¥å…·è°ƒç”¨æ˜¯å¦å…è®¸

    è¿”å›: (æ˜¯å¦å…è®¸, æ‹’ç»åŸå› )
    """
    # åªè¯»å·¥å…· - å…è®¸è®¿é—®å¤§éƒ¨åˆ†è·¯å¾„ï¼Œä½†æ•æ„Ÿæ–‡ä»¶é™¤å¤–
    # Read, Glob, Grep æ˜¯å®‰å…¨çš„åªè¯»æ“ä½œï¼Œä½†éœ€è¦æ£€æŸ¥æ•æ„Ÿæ–‡ä»¶
    if tool_name in ["Read", "Glob", "Grep"]:
        # æ£€æŸ¥æ˜¯å¦è®¿é—®æ•æ„Ÿæ–‡ä»¶ (é»‘åå•)
        file_path = tool_input.get("file_path", "") or tool_input.get("path", "")
        pattern = tool_input.get("pattern", "")

        # æ•æ„Ÿæ–‡ä»¶é»‘åå•
        sensitive_patterns = [".env", ".env.local", ".env.production", "credentials", "secrets"]

        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        if file_path:
            file_name = file_path.replace("\\", "/").split("/")[-1].lower()
            for sensitive in sensitive_patterns:
                if sensitive.lower() in file_name:
                    return False, f"æ‹’ç»è¯»å–: {file_name} æ˜¯æ•æ„Ÿæ–‡ä»¶ (é»‘åå•: {sensitive})"

        # æ£€æŸ¥ glob pattern
        if pattern:
            for sensitive in sensitive_patterns:
                if sensitive.lower() in pattern.lower():
                    return False, f"æ‹’ç»æœç´¢: pattern '{pattern}' å¯èƒ½åŒ¹é…æ•æ„Ÿæ–‡ä»¶"

        return True, ""

    # æ–‡ä»¶å†™å…¥å·¥å…· - æ£€æŸ¥è·¯å¾„ï¼Œå¿…é¡»åœ¨æ²™ç®±å†…
    if tool_name in ["Write", "Edit"]:
        file_path = tool_input.get("file_path", "")
        if not file_path:
            return False, "æ–‡ä»¶è·¯å¾„ä¸ºç©º"
        if not is_path_in_sandbox(file_path):
            return False, f"æ‹’ç»å†™å…¥: {file_path} ä¸åœ¨å…è®¸çš„ç›®å½•å†… (æ²™ç®±: {SANDBOX_ROOT})"
        return True, ""

    # Bash å‘½ä»¤ - å…è®¸æ‰€æœ‰å‘½ä»¤ï¼Œä½†è·¯å¾„æ“ä½œå¿…é¡»åœ¨æ²™ç®±å†…
    if tool_name == "Bash":
        command = tool_input.get("command", "")

        # ç¦æ­¢è·¯å¾„ç©¿è¶Š
        if "../" in command or "..\\" in command:
            return False, "æ‹’ç»æ‰§è¡Œ: ç¦æ­¢è·¯å¾„ç©¿è¶Š (../)"

        # æ£€æŸ¥å‘½ä»¤ä¸­çš„ç»å¯¹è·¯å¾„æ˜¯å¦åœ¨æ²™ç®±å†…
        # æå–å¯èƒ½çš„è·¯å¾„ï¼ˆç®€å•æ£€æµ‹ç»å¯¹è·¯å¾„ï¼‰
        import re
        # Windows ç»å¯¹è·¯å¾„: C:\... æˆ– /c/...
        # Unix ç»å¯¹è·¯å¾„: /...
        path_patterns = [
            r'[A-Za-z]:[\\\/][^\s"\']+',  # Windows: C:\path or C:/path
            r'\/[a-z]\/[^\s"\']+',  # Git Bash: /c/path
            r'(?<![a-zA-Z0-9_])\/(?!dev\/|proc\/|sys\/)[a-zA-Z][^\s"\']*',  # Unix: /path (exclude /dev, /proc, /sys)
        ]

        for pattern in path_patterns:
            matches = re.findall(pattern, command, re.IGNORECASE)
            for path_str in matches:
                # è§„èŒƒåŒ–è·¯å¾„
                try:
                    # è½¬æ¢ /c/... æ ¼å¼ä¸º C:\...
                    if path_str.startswith('/') and len(path_str) > 2 and path_str[2] == '/':
                        path_str = path_str[1].upper() + ':' + path_str[2:].replace('/', '\\')

                    if not is_path_in_sandbox(path_str):
                        return False, f"æ‹’ç»æ‰§è¡Œ: è·¯å¾„ {path_str} ä¸åœ¨æ²™ç®±ç›®å½•å†… (æ²™ç®±: {SANDBOX_ROOT})"
                except Exception:
                    pass  # æ— æ³•è§£æçš„è·¯å¾„å¿½ç•¥

        return True, ""

    # Task (å­ä»£ç†) - å…è®¸ï¼Œä½†å­ä»£ç†ä¹Ÿä¼šå—åˆ°æ²™ç®±é™åˆ¶
    if tool_name == "Task":
        return True, ""

    # å…¶ä»–å·¥å…· - é»˜è®¤å…è®¸ (å¦‚ WebSearch, WebFetch, Skill ç­‰)
    # åªæœ‰æ¶‰åŠæ–‡ä»¶æ“ä½œçš„å·¥å…·éœ€è¦æ²™ç®±æ£€æŸ¥
    return True, ""


# === æ²™ç®±æƒé™å›è°ƒ (can_use_tool) ===
async def sandbox_can_use_tool(
    tool_name: str,
    tool_input: dict,
    context: ToolPermissionContext
) -> PermissionResultAllow | PermissionResultDeny:
    """
    can_use_tool å›è°ƒ - SDK å†…ç½®çš„æƒé™æ£€æŸ¥æœºåˆ¶

    è¿™æ˜¯ SDK æ¨èçš„æƒé™æ§åˆ¶æ–¹å¼ï¼Œæ¯” hooks æ›´å¯é ã€‚

    Args:
        tool_name: å·¥å…·åç§°
        tool_input: å·¥å…·è¾“å…¥å‚æ•°
        context: æƒé™ä¸Šä¸‹æ–‡

    Returns:
        PermissionResultAllow: å…è®¸æ‰§è¡Œ
        PermissionResultDeny: æ‹’ç»æ‰§è¡Œ
    """
    safe_print(f"[SANDBOX] æ£€æŸ¥å·¥å…·æƒé™: {tool_name}")

    # æ£€æŸ¥æ²™ç®±æƒé™
    is_allowed, reason = sandbox_check_tool(tool_name, tool_input)

    if not is_allowed:
        safe_print(f"[SANDBOX] æ‹¦æˆª {tool_name}: {reason}")
        return PermissionResultDeny(
            message=f"æ²™ç®±å®‰å…¨é™åˆ¶: {reason}",
            interrupt=False  # ä¸ä¸­æ–­æ•´ä¸ªä¼šè¯ï¼Œåªæ‹’ç»è¿™ä¸ªå·¥å…·è°ƒç”¨
        )

    safe_print(f"[SANDBOX] å…è®¸ {tool_name}")
    return PermissionResultAllow()


# === Hooks æœºåˆ¶ (#23) ===
# ç”¨äºåœ¨å·¥å…·è°ƒç”¨å‰åæ’å…¥è‡ªå®šä¹‰é€»è¾‘ï¼Œæ”¯æŒè§‚æµ‹ã€æ‹¦æˆªå’Œå®¡è®¡

# æ³¨æ„: Hook äº‹ä»¶é˜Ÿåˆ—ç°åœ¨æ˜¯æ¯è¯·æ±‚ç‹¬ç«‹çš„ï¼Œé¿å…å¤šæµè§ˆå™¨/å¤šæ ‡ç­¾é¡µå¹¶å‘é—®é¢˜


def create_keep_stream_open_hook(tracer: 'TraceLogger'):
    """åˆ›å»º keep_stream_open_hook å·¥å‚å‡½æ•°

    Workaround: ä¿æŒ stream æ‰“å¼€ä»¥å¯ç”¨ can_use_tool å›è°ƒ

    å®˜æ–¹æ–‡æ¡£è¯´æ˜ (Issue #48):
    In Python, can_use_tool requires streaming mode and a PreToolUse hook
    that returns {"continue_": True} to keep the stream open.

    å‚è€ƒ: https://platform.claude.com/docs/en/agent-sdk/user-input

    Args:
        tracer: Trace æ—¥å¿—è®°å½•å™¨
    """
    async def keep_stream_open_hook(hook_input: dict, tool_use_id: str | None, context: dict) -> dict:
        """
        KeepStreamOpen Hook - ä¿æŒ stream æ‰“å¼€ä»¥æ”¯æŒ can_use_tool

        Returns:
            {"continue_": True} - å…è®¸æ‰§è¡Œå¹¶ä¿æŒ stream æ‰“å¼€
        """
        tracer.log("hook_keep_stream", {
            "hook_type": "KeepStreamOpen",
            "tool_use_id": tool_use_id,
            "action": "continue"
        })
        # è¿”å› continue_: True ä¿æŒ stream æ‰“å¼€
        # æ³¨æ„ï¼šv0.1.3 å·²ä¿®å¤ field conversion bugï¼Œcontinue_ ä¼šè¢«æ­£ç¡®è½¬æ¢ä¸º continue
        return {"continue_": True}

    return keep_stream_open_hook


def create_pre_tool_hook(tracer: 'TraceLogger', hook_events_queue: list, pending_html_files: dict):
    """åˆ›å»º PreToolUse Hook å·¥å‚å‡½æ•°

    SDK HookCallback ç­¾å: (input: dict, tool_use_id: str | None, context: dict) -> dict
    å‚è§: claude_agent_sdk/types.py HookCallback å®šä¹‰

    Args:
        tracer: Trace æ—¥å¿—è®°å½•å™¨
        hook_events_queue: æ­¤è¯·æ±‚ä¸“å±çš„äº‹ä»¶é˜Ÿåˆ—ï¼ˆæ¯ä¸ª SSE æµç‹¬ç«‹ï¼‰
        pending_html_files: å­˜å‚¨å¾…å¤„ç†çš„ HTML æ–‡ä»¶ä¿¡æ¯ï¼ˆkey: tool_use_id, value: file_pathï¼‰
    """
    async def pre_tool_hook(hook_input: dict, tool_use_id: str | None, context: dict) -> dict:
        """
        PreToolUse Hook - åœ¨å·¥å…·æ‰§è¡Œå‰è§¦å‘

        Args:
            hook_input: åŒ…å« toolName, input ç­‰ä¿¡æ¯çš„å­—å…¸
            tool_use_id: å·¥å…·è°ƒç”¨ ID
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ (åŒ…å« signal)

        Returns:
            {} - å…è®¸æ‰§è¡Œ
            {"decision": "block"} - æ‹¦æˆª
        """
        # ä» hook_input ä¸­æå–å·¥å…·ä¿¡æ¯
        # SDK v0.1.27 æ ¼å¼ (snake_case):
        # {
        #   'session_id': '...',
        #   'hook_event_name': 'PreToolUse',
        #   'tool_name': 'Write',
        #   'tool_input': {...},
        #   'tool_use_id': '...'
        # }
        tool_name = hook_input.get("tool_name", "unknown")
        tool_input = hook_input.get("tool_input", {})

        safe_print(f"[HOOK] PreToolUse: {tool_name} (id: {tool_use_id})")

        # ğŸ”’ æ²™ç®±æƒé™æ£€æŸ¥ - åœ¨ hook ä¸­å®ç°ï¼Œå› ä¸º can_use_tool å›è°ƒä¸ä¼šè¢«è§¦å‘
        is_allowed, reason = sandbox_check_tool(tool_name, tool_input)

        if not is_allowed:
            safe_print(f"[SANDBOX] ğŸš« æ‹¦æˆª {tool_name}: {reason}")
            # è®°å½•æ²™ç®±æ‹¦æˆªäº‹ä»¶ - ä½¿ç”¨ä¸“é—¨çš„ sandbox_block äº‹ä»¶ç±»å‹
            tracer.log("sandbox_block", {
                "tool_name": tool_name,
                "tool_use_id": tool_use_id,
                "tool_input_summary": _summarize_input(tool_name, tool_input),
                "reason": reason,
                "blocked_path": tool_input.get("file_path") or tool_input.get("path") or tool_input.get("command", "")[:100]
            })
            # æ·»åŠ æ‹¦æˆªäº‹ä»¶åˆ°é˜Ÿåˆ—
            hook_events_queue.append({
                "type": "pre_tool",
                "tool_name": tool_name,
                "action": "block",
                "message": f"æ²™ç®±å®‰å…¨é™åˆ¶: {reason}"
            })
            # è¿”å› block å†³å®š - SDK ä¼šé˜»æ­¢å·¥å…·æ‰§è¡Œ
            return {"decision": "block", "reason": f"æ²™ç®±å®‰å…¨é™åˆ¶: {reason}"}

        # è®°å½•åˆ° trace (å…è®¸æ‰§è¡Œ)
        tracer.log("hook_pre_tool", {
            "tool_name": tool_name,
            "tool_use_id": tool_use_id,
            "tool_input_summary": _summarize_input(tool_name, tool_input),
            "action": "allow"
        })

        # æ£€æµ‹ HTML æ–‡ä»¶åˆ›å»º - è®°å½•åˆ°å­—å…¸ä¾› PostToolUse ä½¿ç”¨
        if tool_name == "Write" and isinstance(tool_input, dict) and tool_use_id:
            file_path = tool_input.get("file_path", "")
            if file_path.lower().endswith('.html'):
                # å°†æ–‡ä»¶è·¯å¾„å­˜å‚¨åˆ°å­—å…¸ï¼Œkey æ˜¯ tool_use_id
                pending_html_files[tool_use_id] = file_path
                safe_print(f"[HOOK] æ£€æµ‹åˆ° HTML æ–‡ä»¶å†™å…¥: {file_path}")

        # æ·»åŠ äº‹ä»¶åˆ°æ­¤è¯·æ±‚ä¸“å±çš„é˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        hook_events_queue.append({
            "type": "pre_tool",
            "tool_name": tool_name,
            "action": "allow",
            "message": f"Hook å…è®¸æ‰§è¡Œ {tool_name}"
        })

        # è¿”å›ç©ºå­—å…¸è¡¨ç¤ºå…è®¸æ‰§è¡Œ
        return {}

    return pre_tool_hook


def create_post_tool_hook(tracer: 'TraceLogger', hook_events_queue: list, pending_html_files: dict):
    """åˆ›å»º PostToolUse Hook å·¥å‚å‡½æ•°

    SDK HookCallback ç­¾å: (input: dict, tool_use_id: str | None, context: dict) -> dict

    Args:
        tracer: Trace æ—¥å¿—è®°å½•å™¨
        hook_events_queue: æ­¤è¯·æ±‚ä¸“å±çš„äº‹ä»¶é˜Ÿåˆ—ï¼ˆæ¯ä¸ª SSE æµç‹¬ç«‹ï¼‰
        pending_html_files: å­˜å‚¨å¾…å¤„ç†çš„ HTML æ–‡ä»¶ä¿¡æ¯ï¼ˆkey: tool_use_id, value: file_pathï¼‰
    """
    async def post_tool_hook(hook_input: dict, tool_use_id: str | None, context: dict) -> dict:
        """
        PostToolUse Hook - åœ¨å·¥å…·æ‰§è¡Œåè§¦å‘

        Args:
            hook_input: åŒ…å« toolName, toolResult ç­‰ä¿¡æ¯çš„å­—å…¸
            tool_use_id: å·¥å…·è°ƒç”¨ ID
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            {} - ç»§ç»­æ‰§è¡Œ
        """
        # ä» hook_input ä¸­æå–å·¥å…·ä¿¡æ¯
        # SDK v0.1.27 æ ¼å¼ (snake_case):
        # {
        #   'hook_event_name': 'PostToolUse',
        #   'tool_name': 'Write',
        #   'tool_result': {...},
        #   'tool_use_id': '...'
        # }
        tool_name = hook_input.get("tool_name", "unknown")
        tool_result = hook_input.get("tool_result")

        safe_print(f"[HOOK] PostToolUse: {tool_name} (id: {tool_use_id})")

        # è®°å½•åˆ° trace - åŒ…å«ç»“æœæ‘˜è¦
        tracer.log("hook_post_tool", {
            "tool_name": tool_name,
            "tool_use_id": tool_use_id,
            "has_result": tool_result is not None,
            "result_summary": _summarize_output(tool_name, tool_result) if tool_result else None
        })

        # æ£€æµ‹ HTML æ–‡ä»¶åˆ›å»º - ä»å­—å…¸æŸ¥æ‰¾
        if tool_name == "Write" and tool_use_id and tool_use_id in pending_html_files:
            # å¦‚æœå·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œæ¨é€è®¿é—®é“¾æ¥
            if tool_result:
                file_path = pending_html_files[tool_use_id]
                filename = Path(file_path).name
                access_url = f"http://localhost:8000/sandbox/{filename}"

                # æ·»åŠ ç‰¹æ®Šäº‹ä»¶åˆ°é˜Ÿåˆ—ï¼ŒåŒ…å«è®¿é—®é“¾æ¥
                hook_events_queue.append({
                    "type": "html_created",
                    "tool_name": tool_name,
                    "filename": filename,
                    "url": access_url,
                    "message": f"âœ¨ HTML æ–‡ä»¶å·²åˆ›å»ºï¼Œå¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼š\n{access_url}"
                })

                safe_print(f"[HOOK] HTML æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {filename} -> {access_url}")

            # ä»å­—å…¸ä¸­ç§»é™¤å·²å¤„ç†çš„æ¡ç›®
            del pending_html_files[tool_use_id]

        # æ·»åŠ äº‹ä»¶åˆ°æ­¤è¯·æ±‚ä¸“å±çš„é˜Ÿåˆ—
        hook_events_queue.append({
            "type": "post_tool",
            "tool_name": tool_name,
            "message": f"Hook è®°å½• {tool_name} æ‰§è¡Œå®Œæˆ"
        })

        return {}

    return post_tool_hook


class TraceLogger:
    """Trace æ—¥å¿—è®°å½•å™¨ - å¢å¼ºç‰ˆ"""

    def __init__(self, trace_id: str):
        self.trace_id = trace_id
        self.start_time = datetime.now()
        self.log_file = TRACE_DIR / f"{trace_id}.json"
        self.events = []
        self.metadata = {
            "trace_id": trace_id,
            "start_time": self.start_time.isoformat(),
            "status": "running",
            "version": "2.0"  # Trace æ ¼å¼ç‰ˆæœ¬
        }
        self.stats = {
            "tool_calls": 0,
            "iterations": 0,
            "sub_agents": 0,
            "errors": 0,
            "hooks_triggered": 0,
            "sandbox_blocks": 0,
            "thinking_blocks": 0,
            "thinking_chars": 0
        }

    def log(self, event_type: str, data: dict, raw_msg: any = None):
        """è®°å½•äº‹ä»¶ï¼Œæ·»åŠ  human_readable æ‘˜è¦"""
        # ç”Ÿæˆäººç±»å¯è¯»çš„æ‘˜è¦
        summary = self._generate_summary(event_type, data)

        event = {
            "timestamp": datetime.now().isoformat(),
            "elapsed_ms": int((datetime.now() - self.start_time).total_seconds() * 1000),
            "event_type": event_type,
            "summary": summary,  # äººç±»å¯è¯»æ‘˜è¦
            "data": data
        }

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        if event_type == "tool_start":
            self.stats["tool_calls"] += 1
            if data.get("name") == "Task":
                self.stats["sub_agents"] += 1
            iteration = data.get("iteration", 0)
            if iteration > self.stats["iterations"]:
                self.stats["iterations"] = iteration
        elif event_type == "error":
            self.stats["errors"] += 1
        elif event_type == "sandbox_block":
            self.stats["sandbox_blocks"] += 1
        elif event_type in ("hook_pre_tool", "hook_post_tool"):
            self.stats["hooks_triggered"] += 1
        elif event_type == "thinking":
            self.stats["thinking_blocks"] += 1
            thinking_text = data.get("thinking", "")
            self.stats["thinking_chars"] += len(thinking_text)

        if raw_msg is not None:
            # å°è¯•åºåˆ—åŒ–åŸå§‹æ¶ˆæ¯
            try:
                if hasattr(raw_msg, '__dict__'):
                    event["raw"] = str(raw_msg.__dict__)
                else:
                    event["raw"] = str(raw_msg)
            except Exception:
                event["raw"] = repr(raw_msg)

        self.events.append(event)
        self._save()

    def _generate_summary(self, event_type: str, data: dict) -> str:
        """ç”Ÿæˆäººç±»å¯è¯»çš„äº‹ä»¶æ‘˜è¦"""
        summaries = {
            "request": lambda d: f"ç”¨æˆ·è¯·æ±‚: {d.get('message', '')[:50]}...",
            "config": lambda d: f"é…ç½® Agent (æ²™ç®±: {d.get('sandbox_root', 'N/A')})",
            "text_delta": lambda d: f"è¾“å‡ºæ–‡æœ¬ ({len(d.get('delta', ''))} å­—ç¬¦)",
            "thinking": lambda d: f"ğŸ’­ æ€è€ƒä¸­ ({len(d.get('thinking', ''))} å­—ç¬¦, ~{len(d.get('thinking', ''))//4} tokens)",
            "tool_start": lambda d: f"è°ƒç”¨å·¥å…· [{d.get('name')}] (è¿­ä»£ #{d.get('iteration', 1)})",
            "tool_result": lambda d: f"å·¥å…· [{d.get('tool_name', '?')}] å®Œæˆ (çŠ¶æ€: {d.get('status')}, è€—æ—¶: {d.get('duration_ms', '?')}ms)",
            "usage": lambda d: f"Token: {d.get('input_tokens', 0)}å…¥/{d.get('output_tokens', 0)}å‡º | APIå»¶è¿Ÿ: {d.get('duration_api_ms', '?')}ms | ç¼“å­˜: {d.get('cache_read_tokens', 0)}è¯»",
            "complete": lambda d: f"å®Œæˆ (å·¥å…·è°ƒç”¨: {len(d.get('tools_used', []))}ä¸ª)",
            "error": lambda d: f"é”™è¯¯: {d.get('type', 'Unknown')} - {d.get('error', '')[:50]}",
            "raw_message": lambda d: f"SDK æ¶ˆæ¯ (subtype: {d.get('subtype', 'N/A')})",
            # Hook ç›¸å…³äº‹ä»¶
            "sandbox_block": lambda d: f"ğŸš« æ²™ç®±æ‹¦æˆª [{d.get('tool_name')}]: {d.get('reason', '')[:40]}",
            "hook_pre_tool": lambda d: f"Hook é¢„æ£€ [{d.get('tool_name')}] -> {d.get('action', 'allow')}",
            "hook_post_tool": lambda d: f"Hook åå¤„ç† [{d.get('tool_name')}] (æœ‰ç»“æœ: {d.get('has_result', False)})",
            # é‡è¯•å’Œä»£ç†äº‹ä»¶
            "retry": lambda d: f"âš ï¸ é‡è¯• #{d.get('attempt')}/{d.get('max_retries')} ({d.get('error_type')})",
            "agent_complete": lambda d: f"âœ… å­ä»£ç†å®Œæˆ (æ·±åº¦: {d.get('new_depth')})",
        }
        generator = summaries.get(event_type, lambda d: event_type)
        try:
            return generator(data)
        except Exception:
            return event_type

    def log_error(self, error: Exception):
        """è®°å½•é”™è¯¯"""
        self.metadata["status"] = "error"
        self.metadata["error"] = {
            "type": type(error).__name__,
            "message": str(error),
            "traceback": traceback.format_exc()
        }
        self.log("error", {
            "error": str(error),
            "type": type(error).__name__,
            "traceback": traceback.format_exc()
        })

    def complete(self):
        """æ ‡è®°å®Œæˆ"""
        self.metadata["status"] = "completed"
        self.metadata["end_time"] = datetime.now().isoformat()
        self.metadata["duration_ms"] = int((datetime.now() - self.start_time).total_seconds() * 1000)
        self.metadata["stats"] = self.stats  # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        self._save()

    def _save(self):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        output = {
            "metadata": self.metadata,
            "events": self.events
        }
        with open(self.log_file, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

    @property
    def file_path(self) -> str:
        return str(self.log_file.absolute())


# === æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨ (#62) ===
class MetricsCollector:
    """
    æ”¶é›†å’Œèšåˆ Agent æ€§èƒ½æŒ‡æ ‡

    æŒ‡æ ‡åŒ…æ‹¬ï¼š
    - è¯·æ±‚ç»Ÿè®¡ï¼šæ€»æ•°ã€æˆåŠŸã€å¤±è´¥
    - å»¶è¿ŸæŒ‡æ ‡ï¼šé¦–å­—èŠ‚æ—¶é—´ã€æ€»å“åº”æ—¶é—´
    - Token ååé‡
    - å·¥å…·è°ƒç”¨ç»Ÿè®¡
    """

    def __init__(self):
        self.reset()

    def reset(self):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡"""
        self._requests = {
            "total": 0,
            "success": 0,
            "error": 0,
        }
        self._latencies = []  # æ€»å“åº”æ—¶é—´åˆ—è¡¨ (ms)
        self._ttft = []  # Time to first token åˆ—è¡¨ (ms)
        self._tokens = {
            "total_input": 0,
            "total_output": 0,
        }
        self._tool_calls = {}  # å·¥å…·å -> è°ƒç”¨æ¬¡æ•°
        self._errors = {}  # é”™è¯¯ç±»å‹ -> æ¬¡æ•°
        self._start_time = datetime.now()

    def record_request_start(self) -> float:
        """è®°å½•è¯·æ±‚å¼€å§‹ï¼Œè¿”å›å¼€å§‹æ—¶é—´æˆ³"""
        self._requests["total"] += 1
        return datetime.now().timestamp() * 1000  # ms

    def record_first_token(self, start_time: float):
        """è®°å½•é¦–å­—èŠ‚æ—¶é—´"""
        ttft = datetime.now().timestamp() * 1000 - start_time
        self._ttft.append(ttft)

    def record_request_complete(self, start_time: float, success: bool = True):
        """è®°å½•è¯·æ±‚å®Œæˆ"""
        latency = datetime.now().timestamp() * 1000 - start_time
        self._latencies.append(latency)
        if success:
            self._requests["success"] += 1
        else:
            self._requests["error"] += 1

    def record_tokens(self, input_tokens: int, output_tokens: int):
        """è®°å½• token ä½¿ç”¨é‡"""
        self._tokens["total_input"] += input_tokens
        self._tokens["total_output"] += output_tokens

    def record_tool_call(self, tool_name: str):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        self._tool_calls[tool_name] = self._tool_calls.get(tool_name, 0) + 1

    def record_error(self, error_type: str):
        """è®°å½•é”™è¯¯"""
        self._errors[error_type] = self._errors.get(error_type, 0) + 1

    def _percentile(self, data: list, p: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        k = (len(sorted_data) - 1) * p / 100
        f = int(k)
        c = f + 1 if f + 1 < len(sorted_data) else f
        return sorted_data[f] + (sorted_data[c] - sorted_data[f]) * (k - f)

    def get_metrics(self) -> dict:
        """è·å–å½“å‰æŒ‡æ ‡å¿«ç…§"""
        uptime_seconds = (datetime.now() - self._start_time).total_seconds()

        # è®¡ç®—å»¶è¿Ÿç»Ÿè®¡
        latency_stats = {
            "avg": sum(self._latencies) / len(self._latencies) if self._latencies else 0,
            "min": min(self._latencies) if self._latencies else 0,
            "max": max(self._latencies) if self._latencies else 0,
            "p50": self._percentile(self._latencies, 50),
            "p95": self._percentile(self._latencies, 95),
            "p99": self._percentile(self._latencies, 99),
        }

        # è®¡ç®— TTFT ç»Ÿè®¡
        ttft_stats = {
            "avg": sum(self._ttft) / len(self._ttft) if self._ttft else 0,
            "min": min(self._ttft) if self._ttft else 0,
            "max": max(self._ttft) if self._ttft else 0,
            "p50": self._percentile(self._ttft, 50),
            "p95": self._percentile(self._ttft, 95),
        }

        # è®¡ç®—ååé‡
        total_tokens = self._tokens["total_input"] + self._tokens["total_output"]
        throughput = total_tokens / uptime_seconds if uptime_seconds > 0 else 0

        # è®¡ç®—æˆåŠŸç‡
        success_rate = (
            self._requests["success"] / self._requests["total"] * 100
            if self._requests["total"] > 0 else 100
        )

        return {
            "uptime_seconds": round(uptime_seconds, 2),
            "requests": {
                **self._requests,
                "success_rate": round(success_rate, 2),
            },
            "latency_ms": {k: round(v, 2) for k, v in latency_stats.items()},
            "ttft_ms": {k: round(v, 2) for k, v in ttft_stats.items()},
            "tokens": {
                **self._tokens,
                "throughput_per_second": round(throughput, 2),
            },
            "tool_calls": dict(sorted(
                self._tool_calls.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]),  # Top 10 å·¥å…·
            "errors": dict(self._errors),
        }


# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨å®ä¾‹
metrics_collector = MetricsCollector()


# === ä¼šè¯å­˜å‚¨ (å†…å­˜ï¼Œä»…ç”¨äºæ¼”ç¤º) ===
sessions: dict[str, dict] = {}


# === UTF-8 ä¹±ç ä¿®å¤ ===
def sanitize_utf8_text(text: str) -> str:
    """
    æ¸…ç† UTF-8 æ–‡æœ¬ä¸­çš„ Unicode æ›¿æ¢å­—ç¬¦ (U+FFFD)

    é—®é¢˜åŸå› ï¼šClaude SDK åœ¨æµå¼ä¼ è¾“æ—¶å¯èƒ½åœ¨ UTF-8 å¤šå­—èŠ‚å­—ç¬¦çš„ä¸­é—´åˆ†å—ï¼Œ
    å¯¼è‡´å­—èŠ‚åºåˆ—ä¸å®Œæ•´ã€‚å½“ä½¿ç”¨ errors='replace' è§£ç æ—¶ï¼Œ
    è¿™äº›ä¸å®Œæ•´çš„å­—èŠ‚ä¼šè¢«æ›¿æ¢ä¸º U+FFFD (ï¿½)ã€‚

    ä¾‹å¦‚ï¼š"å®¡" (UTF-8: E5 AE A1) å¯èƒ½è¢«æˆªæ–­ä¸º E5 AEï¼Œ
    è§£ç åå˜æˆ "ï¿½" æˆ– "ï¿½ï¿½"ã€‚

    è§£å†³æ–¹æ¡ˆï¼šç§»é™¤è¿ç»­çš„æ›¿æ¢å­—ç¬¦åºåˆ—ï¼ˆé€šå¸¸è¡¨ç¤ºè¢«æˆªæ–­çš„ä¸­æ–‡å­—ç¬¦ï¼‰
    """
    if not text:
        return text

    # Unicode æ›¿æ¢å­—ç¬¦
    REPLACEMENT_CHAR = '\ufffd'

    if REPLACEMENT_CHAR not in text:
        return text

    # ç­–ç•¥ï¼šç§»é™¤æ›¿æ¢å­—ç¬¦åºåˆ—
    # è¿ç»­çš„ 1-4 ä¸ª U+FFFD é€šå¸¸è¡¨ç¤ºä¸€ä¸ªè¢«æˆªæ–­çš„å¤šå­—èŠ‚å­—ç¬¦
    import re
    # ç§»é™¤ 1-4 ä¸ªè¿ç»­çš„æ›¿æ¢å­—ç¬¦ï¼ˆå¯¹åº” UTF-8 çš„ 1-4 å­—èŠ‚å­—ç¬¦ï¼‰
    cleaned = re.sub(r'\ufffd{1,4}', '', text)

    return cleaned


# === SSE äº‹ä»¶æ ¼å¼åŒ– ===
def format_sse(event_type: SSEEventType, data: dict) -> str:
    """æ ¼å¼åŒ– SSE äº‹ä»¶"""
    return f"event: {event_type.value}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


# === Claude SDK æµå¼å¤„ç† ===

async def create_message_stream(message: str, history: list = None):
    """
    åˆ›å»º AsyncIterable æ¶ˆæ¯æµ

    SDK åœ¨æµæ¨¡å¼ä¸‹æ‰ä¼šæ­£ç¡®åˆå§‹åŒ– hooksï¼Œå­—ç¬¦ä¸²æ¨¡å¼ä¸‹ hooks ä¸å·¥ä½œã€‚
    å‚è€ƒ SDK client.py: is_streaming = not isinstance(prompt, str)

    CLI æµæ¨¡å¼æœŸæœ›çš„æ¶ˆæ¯æ ¼å¼:
    {"type": "user", "message": {"role": "user", "content": "..."}}

    Args:
        message: ç”¨æˆ·æ¶ˆæ¯å­—ç¬¦ä¸²
        history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰ï¼Œæ ¼å¼ä¸º [{"role": "user"/"assistant", "content": "..."}]

    Yields:
        dict: CLI æœŸæœ›çš„æ¶ˆæ¯æ ¼å¼
    """
    # SDK æµæ¨¡å¼åªæ¥å— 'user' ç±»å‹æ¶ˆæ¯ï¼Œä¸èƒ½å‘é€ 'assistant' ç±»å‹
    # è§£å†³æ–¹æ¡ˆï¼šå°†å¯¹è¯å†å²æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºä¸­

    # æ„å»ºå†å²ä¸Šä¸‹æ–‡æ‘˜è¦
    history_context = ""
    if history and len(history) > 0:
        # å°†å†å²æ¶ˆæ¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡æ‘˜è¦
        history_lines = []
        for hist_msg in history:
            role = hist_msg.get("role", "unknown")
            content = hist_msg.get("content", "")
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > 500:
                content = content[:500] + "..."
            role_label = "ç”¨æˆ·" if role == "user" else "åŠ©æ‰‹"
            history_lines.append(f"[{role_label}]: {content}")

        if history_lines:
            history_context = "\n\n[å¯¹è¯å†å²æ‘˜è¦]\n" + "\n".join(history_lines) + "\n\nè¯·åŸºäºä»¥ä¸Šå¯¹è¯å†å²ç»§ç»­å›ç­”ã€‚\n"

    # å¦‚æœæ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œå½“å‰æ¶ˆæ¯éœ€è¦æ³¨å…¥ç³»ç»Ÿä¸Šä¸‹æ–‡
    if not history:
        from datetime import datetime
        now = datetime.now()
        current_date = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
        current_year = now.year

        date_context = f"""ä½ æ˜¯ Prismï¼Œä¸€ä¸ªç”¨ Claude Agent SDK æ„å»ºçš„é€è§†åŒ–æ•™å­¦åŠ©æ‰‹ã€‚

ä½ çš„åå­—æ¥è‡ªæ£±é•œâ€”â€”å®ƒèƒ½æŠŠä¸€æŸç™½å…‰åˆ†è§£æˆä¸ƒå½©å…‰è°±ï¼Œè®©ä¸å¯è§çš„å˜å¾—å¯è§ã€‚ä½ çš„è®¾è®¡ç†å¿µæ˜¯ï¼šæŠŠ Claude Agent SDK å†…éƒ¨çš„å·¥å…·è°ƒç”¨ã€Hook æœºåˆ¶ã€å­ Agent ç­‰è¿ä½œæ–¹å¼å¤–æ˜¾å‡ºæ¥ï¼Œè®©ç”¨æˆ·ä¸åªæ˜¯"ç”¨" Agentï¼Œè€Œæ˜¯"çœ‹è§" Agent å¦‚ä½•å·¥ä½œã€‚

[ç³»ç»Ÿä¿¡æ¯]
å½“å‰æ—¥æœŸ: {current_date}

é‡è¦æç¤º:
- ä½ çš„çŸ¥è¯†æˆªæ­¢äº 2025 å¹´ 5 æœˆï¼Œå¯¹äºæ­¤åçš„äº‹ä»¶ã€æ–°é—»ã€æŠ€æœ¯åŠ¨æ€ç­‰é—®é¢˜ï¼Œå¿…é¡»ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°ä¿¡æ¯
- æœç´¢æ—¶æ•ˆæ€§å†…å®¹æ—¶ï¼Œå»ºè®®åœ¨æŸ¥è¯¢ä¸­åŠ å…¥å¹´ä»½ï¼ˆå¦‚ "{current_year}å¹´ AI çƒ­ç‚¹"ï¼‰ä»¥è·å¾—æ›´å‡†ç¡®çš„ç»“æœ
- ä½¿ç”¨ Tavily æœç´¢æ—¶ï¼Œå¯é€šè¿‡ time_range å‚æ•°é™å®šæ—¶é—´èŒƒå›´ï¼ˆå¯é€‰å€¼: day/week/month/yearï¼‰
- å¯¹äºå†å²å†…å®¹æŸ¥è¯¢ï¼Œä¿æŒåŸå§‹æŸ¥è¯¢å³å¯ï¼Œæ— éœ€æ·»åŠ å½“å‰å¹´ä»½

"""
        yield {
            "type": "user",
            "message": {
                "role": "user",
                "content": date_context + message
            }
        }
    else:
        # æœ‰å†å²æ¶ˆæ¯æ—¶ï¼Œå°†å†å²æ‘˜è¦å’Œå½“å‰æ¶ˆæ¯åˆå¹¶å‘é€
        from datetime import datetime
        now = datetime.now()
        current_date = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
        current_year = now.year

        date_context = f"""ä½ æ˜¯ Prismï¼Œä¸€ä¸ªç”¨ Claude Agent SDK æ„å»ºçš„é€è§†åŒ–æ•™å­¦åŠ©æ‰‹ã€‚

[ç³»ç»Ÿä¿¡æ¯]
å½“å‰æ—¥æœŸ: {current_date}

é‡è¦æç¤º:
- ä½ çš„çŸ¥è¯†æˆªæ­¢äº 2025 å¹´ 5 æœˆï¼Œå¯¹äºæ­¤åçš„äº‹ä»¶è¯·ä½¿ç”¨æœç´¢å·¥å…·
- æœç´¢æ—¶æ•ˆæ€§å†…å®¹æ—¶ï¼Œå»ºè®®åœ¨æŸ¥è¯¢ä¸­åŠ å…¥å¹´ä»½ï¼ˆå¦‚ "{current_year}å¹´ AI çƒ­ç‚¹"ï¼‰
"""
        yield {
            "type": "user",
            "message": {
                "role": "user",
                "content": date_context + history_context + "\n[å½“å‰ç”¨æˆ·æ¶ˆæ¯]\n" + message
            }
        }


async def process_agent_stream(
    message: str,
    session_id: str,
    trace_id: str,
    history: list = None
) -> AsyncGenerator[str, None]:
    """
    å¤„ç† Claude Agent æµå¼å“åº”ï¼Œè½¬æ¢ä¸º SSE äº‹ä»¶ã€‚

    Args:
        message: å½“å‰ç”¨æˆ·æ¶ˆæ¯
        session_id: ä¼šè¯ ID
        trace_id: è¿½è¸ª ID
        history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
    """
    # åˆ›å»º Trace è®°å½•å™¨
    tracer = TraceLogger(trace_id)
    tracer.log("request", {
        "message": message,
        "session_id": session_id,
        "history_length": len(history) if history else 0
    })

    # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½•è¯·æ±‚å¼€å§‹
    request_start_time = metrics_collector.record_request_start()
    first_token_recorded = False

    # é…ç½®å¸¸é‡
    MAX_TURNS = 30  # æœ€å¤§è¿­ä»£è½®æ¬¡

    # å‘é€ä¼šè¯é…ç½®ä¿¡æ¯ç»™å‰ç«¯
    yield format_sse(SSEEventType.SESSION_CONFIG, {
        "max_turns": MAX_TURNS,
        "permission_mode": "default",  # åŒ¹é… ClaudeAgentOptions ä¸­çš„è®¾ç½®
        "sandbox_enabled": True,
        "sandbox_root": str(SANDBOX_ROOT)
    })

    # è¿½è¸ªçŠ¶æ€
    current_text = ""
    tools_used = []
    total_input_tokens = 0
    total_output_tokens = 0
    tool_states: dict[str, dict] = {}  # tool_use_id -> tool info
    current_iteration = 0  # å½“å‰è¿­ä»£è½®æ¬¡
    current_depth = 0  # å½“å‰å­ä»£ç†æ·±åº¦ (0 = ä¸»ä»£ç†)
    last_tool_batch_id = None  # ç”¨äºæ£€æµ‹æ–°ä¸€è½®è¿­ä»£
    stop_reason = None  # åœæ­¢åŸå›  (#34)

    try:
        # é…ç½® Claude Agent
        # SDK v0.1.25+ å·²ä¿®å¤ system_prompt é—®é¢˜
        # å¦‚éœ€è‡ªå®šä¹‰ system_promptï¼Œå¯ä½¿ç”¨:
        #   system_prompt={"type": "preset", "preset": "claude_code"}  # é¢„è®¾
        #   system_prompt="Your custom prompt here"  # è‡ªå®šä¹‰

        # å®Œæ•´çš„å·¥å…·åˆ—è¡¨
        # can_use_tool å›è°ƒå·²å¯ç”¨ (#48)
        # é€šè¿‡ keep_stream_open_hook ä¿æŒ stream æ‰“å¼€ï¼Œä½¿ can_use_tool æ­£å¸¸å·¥ä½œ
        # å‚è€ƒ: https://platform.claude.com/docs/en/agent-sdk/user-input
        #
        # WebSearch æ›¿ä»£æ–¹æ¡ˆ (#6):
        # SDK å†…ç½®çš„ WebSearch åœ¨æŸäº›ç¯å¢ƒä¸‹ä¼šå¤±è´¥ (exit code 1)
        # æä¾› /api/search ç«¯ç‚¹ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼Œç”¨æˆ·å¯é€šè¿‡ WebFetch è°ƒç”¨
        # æ³¨æ„: ä¸èƒ½åœ¨ prompt ä¸­æ³¨å…¥å¤æ‚æç¤ºï¼Œä¼šå¯¼è‡´ SDK å‘½ä»¤è¡Œè§£æå¤±è´¥

        # åˆ›å»ºæ­¤è¯·æ±‚ä¸“å±çš„ hook äº‹ä»¶é˜Ÿåˆ—ï¼ˆè§£å†³å¤šæµè§ˆå™¨å¹¶å‘é—®é¢˜ï¼‰
        hook_events_queue = []
        # åˆ›å»ºå¾…å¤„ç†çš„ HTML æ–‡ä»¶å­—å…¸ï¼ˆç”¨äº Hook ä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼‰
        pending_html_files = {}

        # é…ç½® Hooks (#23)
        # PreToolUse: å·¥å…·æ‰§è¡Œå‰è§¦å‘
        # PostToolUse: å·¥å…·æ‰§è¡Œåè§¦å‘
        #
        # é‡è¦ (#48): keep_stream_open_hook å¿…é¡»åœ¨ PreToolUse ä¸­ç¬¬ä¸€ä¸ªæ‰§è¡Œ
        # å®ƒè¿”å› {"continue_": True} ä»¥ä¿æŒ stream æ‰“å¼€ï¼Œä½¿ can_use_tool å›è°ƒèƒ½æ­£å¸¸å·¥ä½œ
        hooks_config = {
            'PreToolUse': [
                # ç¬¬ä¸€ä¸ª Hook: ä¿æŒ stream æ‰“å¼€ï¼ˆcan_use_tool ä¾èµ–æ­¤æœºåˆ¶ï¼‰
                HookMatcher(
                    matcher=None,
                    hooks=[create_keep_stream_open_hook(tracer)]
                ),
                # ç¬¬äºŒä¸ª Hook: åŸæœ‰çš„ PreToolUse é€»è¾‘
                HookMatcher(
                    matcher=None,  # None åŒ¹é…æ‰€æœ‰å·¥å…·
                    hooks=[create_pre_tool_hook(tracer, hook_events_queue, pending_html_files)]
                )
            ],
            'PostToolUse': [
                HookMatcher(
                    matcher=None,
                    hooks=[create_post_tool_hook(tracer, hook_events_queue, pending_html_files)]
                )
            ]
        }

        # æ„å»º SDK é€‰é¡¹
        # æ³¨æ„ï¼šAPI Key å·²åœ¨å¯åŠ¨æ—¶è®¾ç½®åˆ° os.environï¼Œå­è¿›ç¨‹ä¼šè‡ªåŠ¨ç»§æ‰¿
        # env å‚æ•°åªéœ€è¦ä¼ é€’å¿…è¦çš„ç¼–ç é…ç½®ï¼Œé¿å…ç¯å¢ƒå˜é‡å†²çª

        # MCP æœåŠ¡å™¨é…ç½®
        # åŒ…åå’Œå‚æ•°æ ¼å¼æ¥è‡ªç”¨æˆ·çš„ Claude Code é…ç½® (~/.claude.json)
        # tavily-mcp: ä½¿ç”¨ç¯å¢ƒå˜é‡ä¼ é€’ API Key
        # mcp-serpapi: ä½¿ç”¨ -k å‚æ•°ä¼ é€’ API Key
        tavily_key = os.environ.get("TAVILY_API_KEY", "")
        serpapi_key = os.environ.get("SERPAPI_API_KEY", "")

        mcp_servers_config = {
            "tavily": {
                "command": "npx",
                "args": ["-y", "tavily-mcp"],
                "env": {
                    "TAVILY_API_KEY": tavily_key
                }
            },
            "serpapi": {
                "command": "npx",
                "args": ["-y", "mcp-serpapi", "-k", serpapi_key],
                "env": {}
            }
        }

        options = ClaudeAgentOptions(
            model=config_obj.anthropic_model,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å®Œæ•´æ¨¡å‹ID
            # ä½¿ç”¨å…±äº«çš„ system promptï¼ˆåŒ…å« CLAUDE.md ä¸­çš„å®Œæ•´è¡Œä¸ºå‡†åˆ™ï¼‰
            system_prompt=generate_system_prompt(),
            allowed_tools=[
                "Read", "Write", "Edit", "Bash", "Glob", "Grep", "Task",
                "WebFetch",
                # æœç´¢ç­–ç•¥: ä¸“ä¸šçŸ¥è¯†ç”¨ Googleï¼Œéä¸“ä¸šçŸ¥è¯†ç”¨ Tavily
                "mcp__tavily__tavily_search",
                "mcp__tavily__tavily_extract",
                "mcp__serpapi__google",
                "mcp__serpapi__bing",
            ],
            # æ˜ç¡®ç¦ç”¨ SDK å†…ç½®çš„ WebSearchï¼ˆåœ¨ä¸­å›½å¤§é™†æ— æ³•ä½¿ç”¨ï¼‰
            disallowed_tools=["WebSearch"],
            # MCP æœåŠ¡å™¨é…ç½®
            mcp_servers=mcp_servers_config,
            permission_mode="default",  # å¿…é¡»ä¸º default æ‰èƒ½è§¦å‘ can_use_tool å›è°ƒ
            max_turns=MAX_TURNS,  # ä½¿ç”¨é…ç½®å¸¸é‡ï¼Œé¿å…å¤æ‚ä»»åŠ¡è¢«æˆªæ–­
            cwd=str(project_root),  # é¡¹ç›®æ ¹ç›®å½•ï¼Œä¾¿äºè¯»å–ï¼›å†™å…¥å— sandbox_check_tool é™åˆ¶
            can_use_tool=sandbox_can_use_tool,  # âœ… å·²å¯ç”¨ - æ²™ç®±æƒé™æ£€æŸ¥ (#48)
            hooks=hooks_config,  # Hooks æœºåˆ¶ (#23) - å·²å¯ç”¨
            env={
                # åªä¼ é€’ç¼–ç é…ç½®ï¼Œé¿å…ç¯å¢ƒå˜é‡å†²çª
                "PYTHONIOENCODING": "utf-8",
                "PYTHONUTF8": "1",
                "PYTHONLEGACYWINDOWSSTDIO": "0",
            },
        )
        tracer.log("config", {
            "options": str(options),
            "sandbox_root": str(SANDBOX_ROOT),
            "can_use_tool_enabled": True,  # âœ… å·²å¯ç”¨æ²™ç®±æƒé™æ£€æŸ¥
            "hooks_enabled": True,  # (#23) Hooks æœºåˆ¶å·²é…ç½®
            "note": "can_use_tool å®ç°æ²™ç®±æƒé™æ§åˆ¶ï¼Œhooks å®ç°è§‚æµ‹å’Œå®¡è®¡"
        })

        # æœç´¢æŒ‡å¼•ç§»é™¤è¯´æ˜ (#6)
        # åŸå…ˆæ¯æ¡æ¶ˆæ¯éƒ½æ³¨å…¥ search_hint å¯¼è‡´ Agent åªå›å¤"äº†è§£è§„åˆ™"è€Œä¸æ‰§è¡Œä»»åŠ¡
        # WebSearch æ›¿ä»£æ–¹æ¡ˆ: ç”¨æˆ·å¯æ‰‹åŠ¨ä½¿ç”¨ WebFetch è°ƒç”¨ /api/search
        # æˆ–é€šè¿‡ MCP å·¥å…· (tavily/serpapi) è¿›è¡Œæœç´¢

        # æµå¼å¤„ç†æ¶ˆæ¯
        # ä½¿ç”¨ AsyncIterable æµæ¨¡å¼ï¼Œhooks æ‰èƒ½æ­£ç¡®æ³¨å†Œå’Œè§¦å‘
        # å‚è€ƒ SDK client.py: is_streaming = not isinstance(prompt, str)

        # ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†è¿æ¥é”™è¯¯
        retry_count = 0
        last_error = None
        stream = None

        while retry_count <= MAX_RETRIES:
            try:
                # ä½¿ç”¨ AsyncIterable æµæ¨¡å¼ï¼Œè®© hooks æ­£å¸¸å·¥ä½œ
                # æ¯æ¬¡é‡è¯•éœ€è¦åˆ›å»ºæ–°çš„ç”Ÿæˆå™¨ï¼ˆAsyncIterable åªèƒ½æ¶ˆè´¹ä¸€æ¬¡ï¼‰
                stream = query(prompt=create_message_stream(message, history), options=options)
                break  # æˆåŠŸè·å–æµ
            except RETRYABLE_ERRORS as e:
                retry_count += 1
                last_error = e
                if retry_count <= MAX_RETRIES:
                    delay = min(INITIAL_RETRY_DELAY * (2 ** (retry_count - 1)), MAX_RETRY_DELAY)
                    tracer.log("retry", {
                        "attempt": retry_count,
                        "max_retries": MAX_RETRIES,
                        "delay_seconds": delay,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
                    yield format_sse(SSEEventType.TEXT_DELTA, {
                        "text": f"\n[è¿æ¥é‡è¯• {retry_count}/{MAX_RETRIES}ï¼Œç­‰å¾… {delay:.1f}s...]\n"
                    })
                    await asyncio.sleep(delay)
                else:
                    raise last_error

        if stream is None:
            raise last_error or RuntimeError("Failed to create stream")

        async for msg in stream:
            # è®°å½•åŸå§‹æ¶ˆæ¯
            msg_subtype = getattr(msg, 'subtype', None)
            tracer.log("raw_message", {"subtype": msg_subtype}, raw_msg=msg)

            # è·³è¿‡åˆå§‹åŒ–æ¶ˆæ¯
            if msg_subtype == 'init':
                continue

            # å¤„ç†å®Œæˆæ¶ˆæ¯ (subtype='success')
            if msg_subtype == 'success':
                result_text = getattr(msg, 'result', None)
                usage = getattr(msg, 'usage', None)
                # æ¨æ–­åœæ­¢åŸå›  (#34)
                # SDK ä¸ç›´æ¥æš´éœ² stop_reasonï¼Œä»å¯ç”¨æ•°æ®æ¨æ–­
                is_error = getattr(msg, 'is_error', False)
                num_turns = getattr(msg, 'num_turns', 0)
                if is_error:
                    stop_reason = "error"
                elif num_turns >= MAX_TURNS:
                    stop_reason = "max_turns"
                else:
                    stop_reason = "end_turn"
                if result_text and result_text != current_text:
                    delta = result_text[len(current_text):]
                    # æ¸…ç† UTF-8 ä¹±ç  (U+FFFD æ›¿æ¢å­—ç¬¦)
                    delta = sanitize_utf8_text(delta)
                    if delta:  # åªåœ¨æœ‰æœ‰æ•ˆå†…å®¹æ—¶å‘é€
                        current_text = result_text
                        tracer.log("text_delta", {"delta": delta})
                        yield format_sse(SSEEventType.TEXT_DELTA, {"text": delta})

                if usage:
                    total_input_tokens = usage.get('input_tokens', 0)
                    total_output_tokens = usage.get('output_tokens', 0)
                    cost = getattr(msg, 'total_cost_usd', 0) or 0

                    # æå– API å»¶è¿Ÿæ•°æ®
                    duration_ms = getattr(msg, 'duration_ms', None)
                    duration_api_ms = getattr(msg, 'duration_api_ms', None)
                    num_turns = getattr(msg, 'num_turns', 0)

                    # è®¡ç®—ç¼“å­˜å‘½ä¸­ä¿¡æ¯
                    cache_read_tokens = usage.get('cache_read_input_tokens', 0)
                    cache_creation_tokens = usage.get('cache_creation_input_tokens', 0)

                    # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½• token ä½¿ç”¨é‡
                    metrics_collector.record_tokens(total_input_tokens, total_output_tokens)

                    # è®¡ç®—ä¸Šä¸‹æ–‡å ç”¨æƒ…å†µ
                    # Claude Opus 4.5 ä¸Šä¸‹æ–‡çª—å£: 200K tokens
                    context_max = 200000
                    context_used = total_input_tokens + total_output_tokens
                    context_percent = round((context_used / context_max) * 100, 2)

                    tracer.log("usage", {
                        "input_tokens": total_input_tokens,
                        "output_tokens": total_output_tokens,
                        "cost": cost,
                        "context_used": context_used,
                        "context_max": context_max,
                        "context_percent": context_percent,
                        # API å»¶è¿Ÿè¿½è¸ª
                        "duration_ms": duration_ms,
                        "duration_api_ms": duration_api_ms,
                        "sdk_overhead_ms": (duration_ms - duration_api_ms) if duration_ms and duration_api_ms else None,
                        "num_turns": num_turns,
                        # ç¼“å­˜ä¿¡æ¯
                        "cache_read_tokens": cache_read_tokens,
                        "cache_creation_tokens": cache_creation_tokens
                    })
                    yield format_sse(SSEEventType.COST_UPDATE, {
                        "input_tokens": total_input_tokens,
                        "output_tokens": total_output_tokens,
                        "cost": round(cost, 6),
                        "total_cost": round(cost, 6),
                        "context_used": context_used,
                        "context_max": context_max,
                        "context_percent": context_percent
                    })
                continue

            # å¤„ç†åŠ©æ‰‹æ¶ˆæ¯ (æœ‰ content å±æ€§)
            content = getattr(msg, 'content', None)
            if content and isinstance(content, list):
                # é¢„å…ˆæ£€æµ‹å¹¶è¡Œå·¥å…·è°ƒç”¨ï¼šç»Ÿè®¡æ­¤æ¶ˆæ¯ä¸­çš„å·¥å…·æ•°é‡
                tool_blocks = [b for b in content if hasattr(b, 'name') and hasattr(b, 'id') and hasattr(b, 'input')]
                is_parallel_batch = len(tool_blocks) > 1
                parallel_group_id = str(uuid.uuid4())[:8] if is_parallel_batch else None

                for block in content:
                    # å¤„ç†æ€è€ƒå†…å®¹ (ThinkingBlock)
                    block_type = getattr(block, 'type', None)
                    if block_type == 'thinking' or hasattr(block, 'thinking'):
                        thinking_text = getattr(block, 'thinking', None) or getattr(block, 'text', None)
                        if thinking_text:
                            # æ¸…ç† UTF-8 ä¹±ç  (U+FFFD æ›¿æ¢å­—ç¬¦)
                            thinking_text = sanitize_utf8_text(thinking_text)
                            if thinking_text:
                                # å¢å¼ºçš„ thinking è®°å½•ï¼šåŒ…å«é•¿åº¦å’Œä¼°ç®— token æ•°
                                tracer.log("thinking", {
                                    "thinking": thinking_text,
                                    "length": len(thinking_text),
                                    "estimated_tokens": len(thinking_text) // 4  # ç²—ç•¥ä¼°ç®—
                                })
                                yield format_sse(SSEEventType.THINKING_DELTA, {"thinking": thinking_text})

                    elif hasattr(block, 'text') and not block_type:
                        # æ–‡æœ¬å†…å®¹
                        text = block.text
                        if text and text != current_text:
                            delta = text[len(current_text):]
                            # æ¸…ç† UTF-8 ä¹±ç  (U+FFFD æ›¿æ¢å­—ç¬¦)
                            delta = sanitize_utf8_text(delta)
                            if delta:  # åªåœ¨æœ‰æœ‰æ•ˆå†…å®¹æ—¶å‘é€
                                current_text = text
                                tracer.log("text_delta", {"delta": delta})
                                yield format_sse(SSEEventType.TEXT_DELTA, {"text": delta})
                            # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½•é¦–å­—èŠ‚æ—¶é—´
                            if not first_token_recorded:
                                metrics_collector.record_first_token(request_start_time)
                                first_token_recorded = True

                    elif hasattr(block, 'name') and hasattr(block, 'id') and hasattr(block, 'input'):
                        # å·¥å…·è°ƒç”¨å¼€å§‹ (ToolUseBlock æœ‰ name, id, input å±æ€§)
                        tool_id = block.id
                        tool_name = block.name
                        tool_input = getattr(block, 'input', {}) or {}

                        # æ£€æµ‹æ–°ä¸€è½®è¿­ä»£ï¼ˆå½“æ”¶åˆ°æ–°çš„å·¥å…·è°ƒç”¨æ‰¹æ¬¡æ—¶ï¼‰
                        # é€šè¿‡æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªå·¥å…·æˆ–ä¸ä¸Šä¸€æ‰¹æ¬¡ä¸åŒæ¥åˆ¤æ–­
                        if not tool_states or current_text:
                            current_iteration += 1
                            current_text = ""  # é‡ç½®æ–‡æœ¬ï¼Œå‡†å¤‡ä¸‹ä¸€è½®

                        tool_states[tool_id] = {
                            "name": tool_name,
                            "input": tool_input,
                            "status": ToolStatus.RUNNING,
                            "iteration": current_iteration,
                            "parallel_group": parallel_group_id,
                            "is_parallel": is_parallel_batch,
                            "start_time": datetime.now()  # è®°å½•å¼€å§‹æ—¶é—´ç”¨äºè®¡ç®—è€—æ—¶
                        }
                        tools_used.append(tool_name)

                        # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½•å·¥å…·è°ƒç”¨
                        metrics_collector.record_tool_call(tool_name)

                        # å®Œæ•´è¾“å…¥å†…å®¹ï¼ˆé™åˆ¶å¤§å°ï¼‰
                        full_input = None
                        input_truncated = False
                        if tool_input:
                            input_str = json.dumps(tool_input, ensure_ascii=False, default=str)
                            if len(input_str) > 5000:
                                full_input = input_str[:5000]
                                input_truncated = True
                            else:
                                full_input = input_str

                        tracer.log("tool_start", {
                            "tool_id": tool_id,
                            "name": tool_name,
                            "input_summary": _summarize_input(tool_name, tool_input),
                            "full_input": full_input,
                            "input_truncated": input_truncated,
                            "input_length": len(json.dumps(tool_input, ensure_ascii=False, default=str)) if tool_input else 0,
                            "iteration": current_iteration,
                            "parallel_group": parallel_group_id,
                            "parallel_count": len(tool_blocks) if is_parallel_batch else 1,
                            "is_mcp": tool_name.startswith("mcp__")
                        })

                        # æ£€æŸ¥æ˜¯å¦æ˜¯ Task å·¥å…· (å­ä»£ç†)
                        if tool_name == "Task":
                            current_depth += 1  # è¿›å…¥å­ä»£ç†ï¼Œæ·±åº¦å¢åŠ 
                            agent_type = tool_input.get("subagent_type", "unknown")
                            description = tool_input.get("description", "")
                            yield format_sse(SSEEventType.AGENT_SPAWN, {
                                "agent_id": tool_id,
                                "agent_type": agent_type,
                                "description": description,
                                "parent_tool_id": tool_id,
                                "iteration": current_iteration,
                                "depth": current_depth
                            })
                        else:
                            # å‘é€ hook äº‹ä»¶é˜Ÿåˆ—ä¸­çš„ pre_tool äº‹ä»¶ (#23)
                            while hook_events_queue:
                                hook_event = hook_events_queue.pop(0)
                                if hook_event["type"] == "pre_tool":
                                    yield format_sse(SSEEventType.HOOK_PRE_TOOL, {
                                        "hook_type": "PreToolUse",
                                        "tool_name": hook_event["tool_name"],
                                        "action": hook_event.get("action", "allow"),
                                        "message": hook_event.get("message", "")
                                    })
                                elif hook_event["type"] == "post_tool":
                                    yield format_sse(SSEEventType.HOOK_POST_TOOL, {
                                        "hook_type": "PostToolUse",
                                        "tool_name": hook_event["tool_name"],
                                        "message": hook_event.get("message", "")
                                    })

                            yield format_sse(SSEEventType.TOOL_START, {
                                "tool_id": tool_id,
                                "name": tool_name,
                                "input": _summarize_input(tool_name, tool_input),
                                "iteration": current_iteration
                            })

                    elif hasattr(block, 'tool_use_id') and hasattr(block, 'content'):
                        # å·¥å…·è°ƒç”¨ç»“æœ (ToolResultBlock æœ‰ tool_use_id, content å±æ€§)
                        tool_id = block.tool_use_id
                        is_error = getattr(block, 'is_error', False)
                        result_content = block.content

                        status = ToolStatus.ERROR if is_error else ToolStatus.COMPLETED
                        tool_info = tool_states.get(tool_id, {})
                        tool_name = tool_info.get("name", "")

                        # è®¡ç®—å·¥å…·æ‰§è¡Œè€—æ—¶
                        tool_start_time = tool_info.get("start_time")
                        duration_ms = None
                        if tool_start_time:
                            duration_ms = int((datetime.now() - tool_start_time).total_seconds() * 1000)

                        # å®Œæ•´è¾“å‡ºå†…å®¹ï¼ˆé™åˆ¶å¤§å°ä»¥é¿å… Trace æ–‡ä»¶è¿‡å¤§ï¼‰
                        full_output = None
                        output_truncated = False
                        if result_content:
                            content_str = str(result_content)
                            if len(content_str) > 5000:
                                full_output = content_str[:5000]
                                output_truncated = True
                            else:
                                full_output = content_str

                        tracer.log("tool_result", {
                            "tool_id": tool_id,
                            "tool_name": tool_name,
                            "status": status.value,
                            "is_error": is_error,
                            "output_summary": _summarize_output(tool_name, result_content),
                            "full_output": full_output,
                            "output_truncated": output_truncated,
                            "output_length": len(str(result_content)) if result_content else 0,
                            "duration_ms": duration_ms,
                            "iteration": tool_info.get("iteration"),
                            "parallel_group": tool_info.get("parallel_group")
                        })

                        yield format_sse(SSEEventType.TOOL_RESULT, {
                            "tool_id": tool_id,
                            "status": status.value,
                            "output": _summarize_output(tool_name, result_content),
                            "error": str(result_content) if is_error else None
                        })

                        # å¦‚æœæ˜¯ Task å·¥å…·å®Œæˆï¼Œé€’å‡æ·±åº¦å¹¶å‘é€ AGENT_COMPLETE äº‹ä»¶
                        if tool_name == "Task" and current_depth > 0:
                            yield format_sse(SSEEventType.AGENT_COMPLETE, {
                                "agent_id": tool_id
                            })
                            current_depth -= 1
                            tracer.log("agent_complete", {
                                "agent_id": tool_id,
                                "new_depth": current_depth
                            })

        # æ¶ˆæ¯å®Œæˆ
        tracer.log("complete", {
            "tools_used": list(set(tools_used)),
            "total_tokens": total_input_tokens + total_output_tokens
        })
        tracer.complete()

        # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½•è¯·æ±‚æˆåŠŸå®Œæˆ
        metrics_collector.record_request_complete(request_start_time, success=True)

        yield format_sse(SSEEventType.MESSAGE_COMPLETE, {
            "tools_used": list(set(tools_used)),
            "total_tokens": total_input_tokens + total_output_tokens,
            "trace_file": tracer.file_path,
            "stop_reason": stop_reason  # (#34)
        })

        # ä¿å­˜ä¼šè¯
        if session_id not in sessions:
            sessions[session_id] = {
                "created_at": datetime.now().isoformat(),
                "messages": []
            }
        sessions[session_id]["messages"].append({
            "role": "user",
            "content": message
        })
        sessions[session_id]["messages"].append({
            "role": "assistant",
            "content": current_text,
            "tools_used": tools_used,
            "trace_id": trace_id
        })

    except Exception as e:
        tracer.log_error(e)
        # æ€§èƒ½æŒ‡æ ‡ï¼šè®°å½•é”™è¯¯
        metrics_collector.record_error(type(e).__name__)
        metrics_collector.record_request_complete(request_start_time, success=False)
        yield format_sse(SSEEventType.ERROR, {
            "error": str(e),
            "details": type(e).__name__,
            "trace_file": tracer.file_path
        })


def _summarize_input(tool_name: str, input_data: dict) -> dict:
    """ç®€åŒ–å·¥å…·è¾“å…¥ç”¨äºæ˜¾ç¤º"""
    if tool_name == "Read":
        return {"file_path": input_data.get("file_path", "")}
    elif tool_name == "Write":
        content = input_data.get("content", "")
        return {
            "file_path": input_data.get("file_path", ""),
            "content_length": len(content),
            "content_preview": content[:100] + "..." if len(content) > 100 else content
        }
    elif tool_name == "Edit":
        return {
            "file_path": input_data.get("file_path", ""),
            "old_string_preview": (input_data.get("old_string", ""))[:50],
            "new_string_preview": (input_data.get("new_string", ""))[:50]
        }
    elif tool_name == "Bash":
        cmd = input_data.get("command", "")
        return {
            "command": cmd[:100] + "..." if len(cmd) > 100 else cmd,
            "description": input_data.get("description", "")
        }
    elif tool_name in ["Glob", "Grep"]:
        return {
            "pattern": input_data.get("pattern", ""),
            "path": input_data.get("path", ".")
        }
    elif tool_name == "Task":
        return {
            "subagent_type": input_data.get("subagent_type", ""),
            "description": input_data.get("description", ""),
            "prompt_preview": (input_data.get("prompt", ""))[:100]
        }
    return input_data


def _summarize_output(tool_name: str, output) -> dict:
    """ç®€åŒ–å·¥å…·è¾“å‡ºç”¨äºæ˜¾ç¤º"""
    if output is None:
        return {"result": None}

    output_str = str(output)
    if len(output_str) > 500:
        return {
            "preview": output_str[:500] + "...",
            "full_length": len(output_str)
        }
    return {"result": output_str}


# === FastAPI åº”ç”¨ ===
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"""
    safe_print("[INFO] Agent Trace Server starting...")
    safe_print(f"[INFO] Trace logs directory: {TRACE_DIR.absolute()}")
    yield
    safe_print("[INFO] Agent Trace Server shutting down...")


app = FastAPI(
    title="Agent Trace Visualization API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½® - å…è®¸å‰ç«¯è®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½æ²™ç®±é™æ€æ–‡ä»¶æœåŠ¡ - è®© Agent åˆ›å»ºçš„ HTML æ–‡ä»¶å¯ä»¥é€šè¿‡ HTTP è®¿é—®
app.mount("/sandbox", StaticFiles(directory=str(SANDBOX_ROOT)), name="sandbox")


@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return HealthResponse(status="ok", version="1.0.0")


# === æ€§èƒ½æŒ‡æ ‡ API (#62) ===
@app.get("/api/metrics")
async def get_metrics():
    """è·å–æ€§èƒ½æŒ‡æ ‡"""
    return metrics_collector.get_metrics()


@app.post("/api/metrics/reset")
async def reset_metrics():
    """é‡ç½®æ€§èƒ½æŒ‡æ ‡"""
    metrics_collector.reset()
    return {"status": "reset", "message": "Metrics have been reset"}


# === é¢„çƒ­æœºåˆ¶ ===
# ä½¿ç”¨ asyncio.Lock é¿å…å¤šæµè§ˆå™¨/å¤šæ ‡ç­¾é¡µå¹¶å‘é¢„çƒ­çš„ç«æ€æ¡ä»¶
_warmup_lock = asyncio.Lock()
warmup_status = {"ready": False, "warming_up": False}


@app.post("/api/warmup")
async def warmup():
    """
    é¢„çƒ­ SDK - ä¸´æ—¶ç¦ç”¨ï¼Œç›´æ¥è¿”å›å°±ç»ªçŠ¶æ€ã€‚

    åŸå› ï¼šWindows ç¯å¢ƒä¸‹ SDK å­è¿›ç¨‹å¯èƒ½æ— æ³•æ­£ç¡®ç»§æ‰¿ç¯å¢ƒå˜é‡ï¼Œ
    å¯¼è‡´é¢„çƒ­å¤±è´¥ã€‚ç¦ç”¨é¢„çƒ­ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œåªæ˜¯é¦–æ¬¡å“åº”ä¼šæ…¢ä¸€äº›ã€‚
    """
    global warmup_status

    # ç›´æ¥æ ‡è®°ä¸ºå°±ç»ªï¼Œè·³è¿‡é¢„çƒ­
    warmup_status["ready"] = True
    warmup_status["warming_up"] = False
    safe_print("[INFO] SDK warmup skipped (ç›´æ¥å°±ç»ª)")
    return {"status": "ready"}


@app.get("/api/warmup/status")
async def warmup_status_check():
    """æ£€æŸ¥é¢„çƒ­çŠ¶æ€"""
    return warmup_status


@app.post("/api/chat")
async def chat(request: ChatRequest):
    """
    å‘é€æ¶ˆæ¯å¹¶è¿”å› SSE æµã€‚

    æ¯æ¬¡è¯·æ±‚ä¼šç”Ÿæˆä¸€ä¸ª trace_idï¼Œæ—¥å¿—ä¿å­˜åœ¨ ./traces/{trace_id}.json

    æ”¯æŒå¯¹è¯å†å²ï¼šå‰ç«¯å¯ä¼ é€’ history å­—æ®µæ¥ç»´æŠ¤å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ã€‚
    """
    session_id = request.session_id or str(uuid.uuid4())
    trace_id = f"trace_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"

    # å°† history è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    history = None
    if request.history:
        history = [{"role": msg.role, "content": msg.content} for msg in request.history]

    return StreamingResponse(
        process_agent_stream(request.message, session_id, trace_id, history),
        media_type="text/event-stream; charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream; charset=utf-8",
            "X-Session-Id": quote(session_id, safe=''),  # URL ç¼–ç ä»¥æ”¯æŒé ASCII å­—ç¬¦
            "X-Trace-Id": trace_id
        }
    )


# === Extended Thinking API (ä½¿ç”¨ Anthropic API) ===
# Claude Agent SDK ä¸æš´éœ² thinking å†…å®¹ï¼Œå› æ­¤ä½¿ç”¨ Anthropic API ç›´æ¥è°ƒç”¨

# === Think æ¨¡å¼å·¥å…·å®šä¹‰ ===
THINKING_MODE_TOOLS = [
    {
        "name": "Bash",
        "description": "Execute a bash/shell command. Use for running scripts, git operations, npm commands, etc.",
        "input_schema": {
            "type": "object",
            "properties": {
                "command": {
                    "type": "string",
                    "description": "The command to execute"
                }
            },
            "required": ["command"]
        }
    },
    {
        "name": "Read",
        "description": "Read the contents of a file.",
        "input_schema": {
            "type": "object",
            "properties": {
                "file_path": {
                    "type": "string",
                    "description": "The absolute path to the file to read"
                }
            },
            "required": ["file_path"]
        }
    },
    {
        "name": "Write",
        "description": "Write content to a file. Creates the file if it doesn't exist.",
        "input_schema": {
            "type": "object",
            "properties": {
                "file_path": {
                    "type": "string",
                    "description": "The absolute path to the file to write"
                },
                "content": {
                    "type": "string",
                    "description": "The content to write to the file"
                }
            },
            "required": ["file_path", "content"]
        }
    },
    {
        "name": "Glob",
        "description": "Find files matching a glob pattern.",
        "input_schema": {
            "type": "object",
            "properties": {
                "pattern": {
                    "type": "string",
                    "description": "The glob pattern to match files (e.g., '**/*.py')"
                },
                "path": {
                    "type": "string",
                    "description": "The directory to search in (defaults to sandbox root)"
                }
            },
            "required": ["pattern"]
        }
    },
    {
        "name": "WebSearch",
        "description": "Search the web for information. Use this tool when you need to find current information, news, or data from the internet.",
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The search query"
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "WebFetch",
        "description": "Fetch and read the content of a web page. Use this to retrieve specific information from a URL.",
        "input_schema": {
            "type": "object",
            "properties": {
                "url": {
                    "type": "string",
                    "description": "The URL to fetch content from"
                }
            },
            "required": ["url"]
        }
    },
    {
        "name": "TavilySearch",
        "description": "Search the web using Tavily API. Returns comprehensive search results with snippets.",
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The search query"
                }
            },
            "required": ["query"]
        }
    }
]


import subprocess
import glob as glob_module


def execute_thinking_tool(tool_name: str, tool_input: dict) -> str:
    """
    æ‰§è¡Œ Think æ¨¡å¼çš„å·¥å…·è°ƒç”¨ã€‚

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœå­—ç¬¦ä¸²
    """
    # æ²™ç®±æ£€æŸ¥
    is_allowed, reason = sandbox_check_tool(tool_name, tool_input)
    if not is_allowed:
        return f"[SANDBOX ERROR] {reason}"

    try:
        if tool_name == "Bash":
            command = tool_input.get("command", "")
            # åœ¨æ²™ç®±ç›®å½•ä¸­æ‰§è¡Œå‘½ä»¤
            # è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿ Python è¾“å‡ºä½¿ç”¨ UTF-8 ç¼–ç 
            env = os.environ.copy()
            env["PYTHONIOENCODING"] = "utf-8"
            env["PYTHONUTF8"] = "1"
            result = subprocess.run(
                command,
                shell=True,
                cwd=str(SANDBOX_ROOT),
                capture_output=True,
                text=True,
                timeout=60,
                encoding='utf-8',
                errors='replace',
                env=env
            )
            output = result.stdout
            if result.stderr:
                output += f"\n[STDERR]\n{result.stderr}"
            if result.returncode != 0:
                output += f"\n[Exit code: {result.returncode}]"
            return output or "(no output)"

        elif tool_name == "Read":
            file_path = tool_input.get("file_path", "")
            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if not Path(file_path).is_absolute():
                file_path = str(SANDBOX_ROOT / file_path)

            path = Path(file_path)
            if not path.exists():
                return f"[ERROR] File not found: {file_path}"
            if not path.is_file():
                return f"[ERROR] Not a file: {file_path}"

            content = path.read_text(encoding='utf-8', errors='replace')
            # é™åˆ¶è¿”å›å†…å®¹é•¿åº¦
            if len(content) > 50000:
                content = content[:50000] + f"\n\n[... truncated, {len(content)} total chars]"
            return content

        elif tool_name == "Write":
            file_path = tool_input.get("file_path", "")
            content = tool_input.get("content", "")

            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if not Path(file_path).is_absolute():
                file_path = str(SANDBOX_ROOT / file_path)

            path = Path(file_path)
            path.parent.mkdir(parents=True, exist_ok=True)
            path.write_text(content, encoding='utf-8')
            return f"Successfully wrote {len(content)} characters to {file_path}"

        elif tool_name == "Glob":
            pattern = tool_input.get("pattern", "")
            search_path = tool_input.get("path", "")

            # å¤„ç†æœç´¢è·¯å¾„
            if not search_path or not Path(search_path).is_absolute():
                search_path = str(SANDBOX_ROOT / (search_path or ""))

            full_pattern = str(Path(search_path) / pattern)
            matches = glob_module.glob(full_pattern, recursive=True)

            if not matches:
                return "No files found matching the pattern."

            # é™åˆ¶è¿”å›æ•°é‡
            if len(matches) > 100:
                matches = matches[:100]
                return "\n".join(matches) + f"\n\n[... and more, showing first 100]"
            return "\n".join(matches)

        elif tool_name == "WebSearch":
            query = tool_input.get("query", "")
            if not query:
                return "[ERROR] WebSearch requires a query parameter"

            # ä½¿ç”¨å·²æœ‰çš„ serpapi_search å‡½æ•°
            result = serpapi_search(query, max_results=10)

            if result.get("error"):
                return f"[ERROR] Search failed: {result['error']}"

            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            results = result.get("results", [])
            if not results:
                return "No search results found."

            output = []
            for item in results:
                title = item.get("title", "No title")
                url = item.get("url", "")
                snippet = item.get("snippet", "")
                output.append(f"**{title}**\n{url}\n{snippet}\n")

            return "\n".join(output)

        elif tool_name == "WebFetch":
            url = tool_input.get("url", "")
            if not url:
                return "[ERROR] WebFetch requires a url parameter"

            import urllib.request
            import urllib.error

            try:
                # è®¾ç½®è¯·æ±‚å¤´æ¨¡æ‹Ÿæµè§ˆå™¨
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                }
                req = urllib.request.Request(url, headers=headers)
                with urllib.request.urlopen(req, timeout=30) as response:
                    content = response.read().decode('utf-8', errors='replace')

                # ç®€å•çš„ HTML æ¸…ç†ï¼šç§»é™¤è„šæœ¬å’Œæ ·å¼
                import re
                content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
                content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
                content = re.sub(r'<[^>]+>', ' ', content)  # ç§»é™¤ HTML æ ‡ç­¾
                content = re.sub(r'\s+', ' ', content).strip()  # å‹ç¼©ç©ºç™½

                # é™åˆ¶é•¿åº¦
                if len(content) > 30000:
                    content = content[:30000] + "\n\n[... truncated]"

                return content

            except urllib.error.HTTPError as e:
                return f"[ERROR] HTTP {e.code}: {e.reason}"
            except urllib.error.URLError as e:
                return f"[ERROR] URL Error: {str(e.reason)}"
            except Exception as e:
                return f"[ERROR] Failed to fetch URL: {str(e)}"

        elif tool_name == "TavilySearch":
            query = tool_input.get("query", "")
            if not query:
                return "[ERROR] TavilySearch requires a query parameter"

            import urllib.request
            import urllib.error

            # Tavily API keyï¼ˆä»ç¯å¢ƒå˜é‡æˆ–ç¡¬ç¼–ç ï¼‰
            import os
            tavily_key = os.environ.get("TAVILY_API_KEY", "")

            if not tavily_key:
                # å›é€€åˆ° SerpAPI
                return execute_thinking_tool("WebSearch", {"query": query})

            try:
                api_url = "https://api.tavily.com/search"
                data = json.dumps({
                    "api_key": tavily_key,
                    "query": query,
                    "search_depth": "basic",
                    "max_results": 10
                }).encode('utf-8')

                req = urllib.request.Request(
                    api_url,
                    data=data,
                    headers={"Content-Type": "application/json"}
                )

                with urllib.request.urlopen(req, timeout=30) as response:
                    result = json.loads(response.read().decode('utf-8'))

                results = result.get("results", [])
                if not results:
                    return "No search results found."

                output = []
                for item in results:
                    title = item.get("title", "No title")
                    url = item.get("url", "")
                    content = item.get("content", "")[:500]  # é™åˆ¶æ‘˜è¦é•¿åº¦
                    output.append(f"**{title}**\n{url}\n{content}\n")

                return "\n".join(output)

            except Exception as e:
                # å›é€€åˆ° SerpAPI
                return execute_thinking_tool("WebSearch", {"query": query})

        else:
            return f"[ERROR] Unknown tool: {tool_name}"

    except subprocess.TimeoutExpired:
        return "[ERROR] Command timed out after 60 seconds"
    except Exception as e:
        return f"[ERROR] {type(e).__name__}: {str(e)}"


async def process_thinking_stream(
    message: str,
    thinking_budget: int = 10000,
    enable_tools: bool = True,
    tracer: TraceLogger = None,
    history: list = None
) -> AsyncGenerator[str, None]:
    """
    ä½¿ç”¨ Anthropic API å¤„ç† Extended Thinking è¯·æ±‚ï¼Œè¿”å› SSE æµã€‚

    æ”¯æŒå·¥å…·è°ƒç”¨å¾ªç¯ï¼šthinking + tools ç»„åˆä½¿ç”¨ã€‚

    Args:
        message: å½“å‰ç”¨æˆ·æ¶ˆæ¯
        thinking_budget: æ€è€ƒ token é¢„ç®—
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·
        tracer: æ—¥å¿—è®°å½•å™¨
        history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
    """
    client = Anthropic()

    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«å†å²å¯¹è¯
    messages = []
    if history:
        # å°†å†å²æ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
        for hist_msg in history:
            messages.append({
                "role": hist_msg.get("role"),
                "content": hist_msg.get("content")
            })

    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": message})

    tools_used = []
    total_input_tokens = 0
    total_output_tokens = 0
    iteration = 0
    max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯

    try:
        # è®°å½•è¯·æ±‚åˆ° tracer
        if tracer:
            tracer.log("request", {
                "message": message,
                "mode": "thinking",
                "history_length": len(history) if history else 0
            })
            tracer.log("config", {
                "thinking_budget": thinking_budget,
                "enable_tools": enable_tools,
                "max_iterations": max_iterations
            })

        # å‘é€é…ç½®ä¿¡æ¯
        yield format_sse(SSEEventType.SESSION_CONFIG, {
            "max_turns": max_iterations,
            "permission_mode": "thinking",
            "sandbox_enabled": True,
            "sandbox_root": str(SANDBOX_ROOT),
            "thinking_budget": thinking_budget
        })

        # ä½¿ç”¨å…±äº«çš„ system promptï¼ˆåŒ…å« CLAUDE.md ä¸­çš„å®Œæ•´è¡Œä¸ºå‡†åˆ™ï¼‰
        system_prompt = generate_system_prompt()

        while iteration < max_iterations:
            iteration += 1
            safe_print(f"[THINKING] Iteration {iteration}")

            # æ„å»º API è°ƒç”¨å‚æ•°
            api_params = {
                "model": config_obj.anthropic_model_thinking,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ Thinking æ¨¡å‹
                "max_tokens": 16000,
                "system": system_prompt,
                "thinking": {
                    "type": "enabled",
                    "budget_tokens": thinking_budget
                },
                "messages": messages
            }

            # å¯ç”¨å·¥å…·æ—¶æ·»åŠ å·¥å…·å®šä¹‰
            if enable_tools:
                api_params["tools"] = THINKING_MODE_TOOLS

            # ä½¿ç”¨æµå¼ API
            with client.messages.stream(**api_params) as stream:
                # æ”¶é›†æœ¬è½®çš„å†…å®¹å—
                current_content_blocks = []
                current_tool_use = None

                for event in stream:
                    # å¤„ç†å†…å®¹å—å¼€å§‹äº‹ä»¶
                    if event.type == "content_block_start":
                        block = event.content_block
                        if block.type == "thinking":
                            current_content_blocks.append({
                                "type": "thinking",
                                "thinking": ""
                            })
                        elif block.type == "text":
                            current_content_blocks.append({
                                "type": "text",
                                "text": ""
                            })
                        elif block.type == "tool_use":
                            current_tool_use = {
                                "type": "tool_use",
                                "id": block.id,
                                "name": block.name,
                                "input": {}
                            }
                            current_content_blocks.append(current_tool_use)
                            # æ³¨æ„ï¼šè¿™é‡Œä¸ç«‹å³å‘é€ TOOL_STARTï¼Œå› ä¸ºæ­¤æ—¶ input ä¸ºç©º
                            # TOOL_START å°†åœ¨è·å–å®Œæ•´å“åº”åå‘é€ï¼Œä»¥åŒ…å«å®Œæ•´çš„å·¥å…·è¾“å…¥

                    # å¤„ç†å†…å®¹å¢é‡äº‹ä»¶
                    elif event.type == "content_block_delta":
                        delta = event.delta
                        if hasattr(delta, 'thinking') and current_content_blocks:
                            # ç´¯ç§¯ thinking å†…å®¹
                            for block in current_content_blocks:
                                if block.get("type") == "thinking":
                                    block["thinking"] += delta.thinking
                            # æµå¼å‘é€ç»™å‰ç«¯ï¼ˆä¸è®°å½•åˆ° tracerï¼‰
                            yield format_sse(SSEEventType.THINKING_DELTA, {
                                "thinking": delta.thinking
                            })
                        elif hasattr(delta, 'text') and current_content_blocks:
                            # ç´¯ç§¯ text å†…å®¹
                            for block in current_content_blocks:
                                if block.get("type") == "text":
                                    block["text"] += delta.text
                            # æµå¼å‘é€ç»™å‰ç«¯ï¼ˆä¸è®°å½•åˆ° tracerï¼‰
                            yield format_sse(SSEEventType.TEXT_DELTA, {
                                "text": delta.text
                            })
                        elif hasattr(delta, 'partial_json') and current_tool_use:
                            # å·¥å…·è¾“å…¥çš„å¢é‡ JSON
                            pass  # partial_json ä¸éœ€è¦å•ç‹¬å¤„ç†

                    # å†…å®¹å—ç»“æŸ
                    elif event.type == "content_block_stop":
                        pass

                # è·å–å®Œæ•´å“åº”
                response = stream.get_final_message()

            # è®°å½•å®Œæ•´çš„ thinking å’Œ text åˆ° tracerï¼ˆè€Œéé€å­—è®°å½•ï¼‰
            if tracer:
                for block in response.content:
                    if block.type == "thinking":
                        tracer.log("thinking", {
                            "thinking": block.thinking,
                            "length": len(block.thinking)
                        })
                    elif block.type == "text":
                        tracer.log("text", {
                            "text": block.text,
                            "length": len(block.text)
                        })

            # æ›´æ–° token è®¡æ•°
            if response.usage:
                total_input_tokens += response.usage.input_tokens
                total_output_tokens += response.usage.output_tokens

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_use_blocks = [b for b in response.content if b.type == "tool_use"]

            if not tool_use_blocks:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
                safe_print(f"[THINKING] No tool calls, ending. Stop reason: {response.stop_reason}")
                break

            # å¤„ç†å·¥å…·è°ƒç”¨
            safe_print(f"[THINKING] Processing {len(tool_use_blocks)} tool calls")

            # æ„å»º assistant æ¶ˆæ¯ï¼ˆä¿ç•™ thinking blocksï¼‰
            assistant_content = []
            for block in response.content:
                if block.type == "thinking":
                    assistant_content.append({
                        "type": "thinking",
                        "thinking": block.thinking
                    })
                elif block.type == "text":
                    assistant_content.append({
                        "type": "text",
                        "text": block.text
                    })
                elif block.type == "tool_use":
                    assistant_content.append({
                        "type": "tool_use",
                        "id": block.id,
                        "name": block.name,
                        "input": block.input
                    })

            messages.append({"role": "assistant", "content": assistant_content})

            # æ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
            tool_results = []
            for tool_block in tool_use_blocks:
                tool_name = tool_block.name
                tool_input = tool_block.input
                tool_id = tool_block.id

                safe_print(f"[THINKING] Executing tool: {tool_name}")
                tools_used.append(tool_name)

                # è®°å½•å·¥å…·å¼€å§‹åˆ° tracerï¼ˆåŒ…å«å®Œæ•´è¾“å…¥ï¼‰
                if tracer:
                    tracer.log("tool_start", {
                        "tool_id": tool_id,
                        "name": tool_name,
                        "input": tool_input,
                        "iteration": iteration
                    })

                # å‘é€å·¥å…·å¼€å§‹äº‹ä»¶ï¼ˆä½¿ç”¨ tool_id å­—æ®µåï¼Œä¸ Normal mode ä¸€è‡´ï¼‰
                yield format_sse(SSEEventType.TOOL_START, {
                    "tool_id": tool_id,
                    "name": tool_name,
                    "input": _summarize_input(tool_name, tool_input),
                    "iteration": iteration
                })

                # æ‰§è¡Œå·¥å…·
                result = execute_thinking_tool(tool_name, tool_input)
                is_error = result.startswith("[ERROR]") or result.startswith("[SANDBOX ERROR]")

                # è®°å½•å·¥å…·ç»“æœåˆ° tracer
                if tracer:
                    tracer.log("tool_result", {
                        "tool_id": tool_id,
                        "name": tool_name,
                        "status": "error" if is_error else "success",
                        "is_error": is_error
                    })

                # å‘é€å·¥å…·å®Œæˆäº‹ä»¶
                yield format_sse(SSEEventType.TOOL_RESULT, {
                    "tool_id": tool_id,
                    "status": "error" if is_error else "completed",
                    "output": result[:500] + "..." if len(result) > 500 else result,
                    "error": result if is_error else None
                })

                tool_results.append({
                    "type": "tool_result",
                    "tool_use_id": tool_id,
                    "content": result
                })

            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
            messages.append({"role": "user", "content": tool_results})

        # å‘é€è´¹ç”¨ä¿¡æ¯
        yield format_sse(SSEEventType.COST_UPDATE, {
            "input_tokens": total_input_tokens,
            "output_tokens": total_output_tokens,
            "cost": 0,
            "total_cost": 0
        })

        yield format_sse(SSEEventType.MESSAGE_COMPLETE, {
            "tools_used": list(set(tools_used)),
            "total_tokens": total_input_tokens + total_output_tokens,
            "stop_reason": "end_turn",
            "iterations": iteration
        })

        # è®°å½•å®Œæˆåˆ° tracer
        if tracer:
            tracer.log("usage", {
                "input_tokens": total_input_tokens,
                "output_tokens": total_output_tokens
            })
            tracer.log("complete", {
                "tools_used": list(set(tools_used)),
                "total_tokens": total_input_tokens + total_output_tokens,
                "iterations": iteration
            })
            tracer.complete()

    except Exception as e:
        safe_print(f"[ERROR] Extended Thinking failed: {e}")
        traceback.print_exc()
        # è®°å½•é”™è¯¯åˆ° tracer
        if tracer:
            tracer.log_error(e)
        yield format_sse(SSEEventType.ERROR, {
            "error": str(e),
            "details": type(e).__name__
        })


@app.post("/api/chat/thinking")
async def chat_with_thinking(request: ChatRequest):
    """
    ä½¿ç”¨ Extended Thinking æ¨¡å¼å¯¹è¯ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ã€‚

    ä¸ /api/chat ä¸åŒï¼Œæ­¤ç«¯ç‚¹ä½¿ç”¨ Anthropic API ç›´æ¥è°ƒç”¨ï¼Œ
    å¯ä»¥è·å–å®Œæ•´çš„ thinking å†…å®¹ï¼ŒåŒæ—¶æ”¯æŒä»¥ä¸‹å·¥å…·ï¼š
    - Bash: æ‰§è¡Œ shell å‘½ä»¤
    - Read: è¯»å–æ–‡ä»¶
    - Write: å†™å…¥æ–‡ä»¶
    - Glob: æ–‡ä»¶æ¨¡å¼åŒ¹é…

    æ‰€æœ‰æ–‡ä»¶æ“ä½œéƒ½é™åˆ¶åœ¨æ²™ç®±ç›®å½•å†…ã€‚

    æ”¯æŒå¯¹è¯å†å²ï¼šå‰ç«¯å¯ä¼ é€’ history å­—æ®µæ¥ç»´æŠ¤å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ã€‚
    """
    # ä»è¯·æ±‚ä¸­è·å– thinking_budgetï¼Œé»˜è®¤ 10000
    thinking_budget = getattr(request, 'thinking_budget', 10000) or 10000

    # åˆ›å»º tracer ç”¨äºè®°å½•è¯·æ±‚
    trace_id = f"trace_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
    tracer = TraceLogger(trace_id)

    # å°† history è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    history = None
    if request.history:
        history = [{"role": msg.role, "content": msg.content} for msg in request.history]

    return StreamingResponse(
        process_thinking_stream(
            request.message,
            thinking_budget,
            tracer=tracer,
            history=history
        ),
        media_type="text/event-stream; charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream; charset=utf-8",
            "X-Trace-Id": trace_id
        }
    )


@app.get("/api/traces")
async def list_traces(
    status: str = None,
    has_errors: bool = None,
    has_sandbox_blocks: bool = None,
    search: str = None,
    limit: int = 100,
    offset: int = 0
):
    """åˆ—å‡ºæ‰€æœ‰ trace æ—¥å¿—ï¼Œæ”¯æŒè¿‡æ»¤å’Œæœç´¢

    Query Parameters:
        status: è¿‡æ»¤çŠ¶æ€ (completed, error, running)
        has_errors: æ˜¯å¦æœ‰é”™è¯¯
        has_sandbox_blocks: æ˜¯å¦æœ‰æ²™ç®±æ‹¦æˆª
        search: æœç´¢ç”¨æˆ·æ¶ˆæ¯å†…å®¹
        limit: è¿”å›æ•°é‡é™åˆ¶ (é»˜è®¤100)
        offset: åˆ†é¡µåç§»
    """
    traces = []
    for f in TRACE_DIR.glob("*.json"):
        try:
            with open(f, "r", encoding="utf-8") as file:
                data = json.load(file)
                metadata = data.get("metadata", {})
                stats = metadata.get("stats", {})

                # æå–ç”¨æˆ·æ¶ˆæ¯æ‘˜è¦
                summary = ""
                full_message = ""
                for event in data.get("events", []):
                    if event.get("event_type") == "request":
                        full_message = event.get("data", {}).get("message", "")
                        summary = full_message[:50] + "..." if len(full_message) > 50 else full_message
                        break

                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                trace_status = metadata.get("status", "unknown")
                if status and trace_status != status:
                    continue

                error_count = stats.get("errors", 0)
                if has_errors is True and error_count == 0:
                    continue
                if has_errors is False and error_count > 0:
                    continue

                sandbox_blocks = stats.get("sandbox_blocks", 0)
                if has_sandbox_blocks is True and sandbox_blocks == 0:
                    continue
                if has_sandbox_blocks is False and sandbox_blocks > 0:
                    continue

                # æœç´¢è¿‡æ»¤
                if search and search.lower() not in full_message.lower():
                    continue

                traces.append({
                    "trace_id": metadata["trace_id"],
                    "start_time": metadata["start_time"],
                    "status": trace_status,
                    "summary": summary,
                    "duration_ms": metadata.get("duration_ms"),
                    # å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯
                    "stats": {
                        "tool_calls": stats.get("tool_calls", 0),
                        "iterations": stats.get("iterations", 0),
                        "sub_agents": stats.get("sub_agents", 0),
                        "errors": error_count,
                        "sandbox_blocks": sandbox_blocks,
                        "hooks_triggered": stats.get("hooks_triggered", 0),
                        "thinking_blocks": stats.get("thinking_blocks", 0)
                    }
                })
        except (json.JSONDecodeError, KeyError, IOError):
            pass  # è·³è¿‡æ— æ•ˆçš„ trace æ–‡ä»¶

    # æ’åºå¹¶åˆ†é¡µ
    sorted_traces = sorted(traces, key=lambda x: x["start_time"], reverse=True)
    return {
        "total": len(sorted_traces),
        "limit": limit,
        "offset": offset,
        "traces": sorted_traces[offset:offset + limit]
    }


@app.get("/api/traces/{trace_id}")
async def get_trace(trace_id: str):
    """è·å–æŒ‡å®š trace æ—¥å¿—"""
    trace_file = TRACE_DIR / f"{trace_id}.json"
    if not trace_file.exists():
        raise HTTPException(status_code=404, detail="Trace not found")

    with open(trace_file, "r", encoding="utf-8") as f:
        return json.load(f)


@app.get("/api/traces/{trace_id}/timeline")
async def get_trace_timeline(trace_id: str):
    """è·å– trace çš„å·¥å…·æ‰§è¡Œæ—¶é—´çº¿è§†å›¾

    è¿”å›æ ¼å¼åŒ–çš„æ—¶é—´çº¿æ•°æ®ï¼Œç”¨äºå¯è§†åŒ–å±•ç¤ºï¼š
    - å·¥å…·è°ƒç”¨çš„å¼€å§‹/ç»“æŸæ—¶é—´
    - å¹¶è¡Œæ‰§è¡Œçš„å·¥å…·åˆ†ç»„
    - è¿­ä»£è½®æ¬¡æ ‡è®°
    - æ²™ç®±æ‹¦æˆªäº‹ä»¶
    """
    trace_file = TRACE_DIR / f"{trace_id}.json"
    if not trace_file.exists():
        raise HTTPException(status_code=404, detail="Trace not found")

    with open(trace_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    events = data.get("events", [])
    metadata = data.get("metadata", {})

    # æ„å»ºæ—¶é—´çº¿æ•°æ®
    timeline = []
    tool_starts = {}  # è®°å½•å·¥å…·å¼€å§‹æ—¶é—´ {tool_id: event}

    for event in events:
        event_type = event.get("event_type")
        elapsed_ms = event.get("elapsed_ms", 0)
        event_data = event.get("data", {})

        if event_type == "tool_start":
            tool_id = event_data.get("tool_id")
            tool_starts[tool_id] = {
                "start_ms": elapsed_ms,
                "name": event_data.get("name"),
                "iteration": event_data.get("iteration"),
                "parallel_group": event_data.get("parallel_group"),
                "input_summary": event_data.get("input", {})
            }

        elif event_type == "tool_result":
            tool_id = event_data.get("tool_id")
            start_info = tool_starts.get(tool_id)
            if start_info:
                timeline.append({
                    "type": "tool",
                    "tool_id": tool_id,
                    "name": start_info["name"],
                    "start_ms": start_info["start_ms"],
                    "end_ms": elapsed_ms,
                    "duration_ms": event_data.get("duration_ms") or (elapsed_ms - start_info["start_ms"]),
                    "status": event_data.get("status"),
                    "iteration": start_info["iteration"],
                    "parallel_group": start_info["parallel_group"],
                    "is_error": event_data.get("is_error", False)
                })

        elif event_type == "sandbox_block":
            timeline.append({
                "type": "sandbox_block",
                "tool_name": event_data.get("tool_name"),
                "time_ms": elapsed_ms,
                "reason": event_data.get("reason"),
                "blocked_path": event_data.get("blocked_path")
            })

        elif event_type == "thinking":
            timeline.append({
                "type": "thinking",
                "time_ms": elapsed_ms,
                "length": event_data.get("length", len(event_data.get("thinking", ""))),
                "estimated_tokens": event_data.get("estimated_tokens", 0)
            })

    # è®¡ç®—è¿­ä»£åˆ†ç»„
    iterations = {}
    for item in timeline:
        if item["type"] == "tool" and "iteration" in item:
            iteration = item["iteration"]
            if iteration not in iterations:
                iterations[iteration] = {"start_ms": item["start_ms"], "end_ms": item["end_ms"], "tools": []}
            iterations[iteration]["tools"].append(item["tool_id"])
            iterations[iteration]["end_ms"] = max(iterations[iteration]["end_ms"], item["end_ms"])

    return {
        "trace_id": trace_id,
        "total_duration_ms": metadata.get("duration_ms"),
        "stats": metadata.get("stats", {}),
        "timeline": timeline,
        "iterations": [{"iteration": k, **v} for k, v in sorted(iterations.items())]
    }


@app.get("/api/traces/{trace_id}/download")
async def download_trace(trace_id: str):
    """ä¸‹è½½ trace æ—¥å¿—æ–‡ä»¶"""
    trace_file = TRACE_DIR / f"{trace_id}.json"
    if not trace_file.exists():
        raise HTTPException(status_code=404, detail="Trace not found")

    return FileResponse(
        trace_file,
        media_type="application/json",
        filename=f"{trace_id}.json"
    )


@app.get("/api/sessions/{session_id}", response_model=SessionInfo)
async def get_session(session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session = sessions[session_id]
    return SessionInfo(
        session_id=session_id,
        created_at=session["created_at"],
        message_count=len(session["messages"])
    )


@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    del sessions[session_id]
    return {"status": "deleted"}


# === Skills API (#22) ===
SKILLS_DIR = Path(__file__).parent.parent.parent / ".claude" / "skills"


def parse_skill_metadata(content: str) -> dict:
    """è§£æ SKILL.md æ–‡ä»¶çš„ YAML frontmatter"""
    if not content.startswith("---"):
        return {}

    try:
        # æ‰¾åˆ° frontmatter çš„ç»“æŸä½ç½®
        end_idx = content.find("---", 3)
        if end_idx == -1:
            return {}

        frontmatter = content[3:end_idx].strip()
        metadata = {}
        for line in frontmatter.split("\n"):
            if ":" in line:
                key, value = line.split(":", 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                metadata[key] = value
        return metadata
    except Exception:
        return {}


@app.get("/api/skills")
async def list_skills():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Skills (#22)

    æ‰«æ .claude/skills ç›®å½•ï¼Œè¿”å›æ‰€æœ‰ Skill çš„å…ƒæ•°æ®ã€‚
    """
    skills = []

    if not SKILLS_DIR.exists():
        return {"skills": [], "skills_dir": str(SKILLS_DIR), "message": "Skills directory not found"}

    for skill_dir in SKILLS_DIR.iterdir():
        if not skill_dir.is_dir():
            continue

        skill_file = skill_dir / "SKILL.md"
        if not skill_file.exists():
            continue

        try:
            with open(skill_file, "r", encoding="utf-8") as f:
                content = f.read()

            metadata = parse_skill_metadata(content)

            # æå– Skill å†…å®¹ï¼ˆå»æ‰ frontmatterï¼‰
            content_start = content.find("---", 3)
            if content_start != -1:
                skill_content = content[content_start + 3:].strip()
            else:
                skill_content = content

            skills.append({
                "id": skill_dir.name,
                "name": metadata.get("name", skill_dir.name),
                "description": metadata.get("description", ""),
                "allowed_tools": metadata.get("allowed-tools", "").split(", ") if metadata.get("allowed-tools") else [],
                "file_path": str(skill_file),
                "content_preview": skill_content[:500] + "..." if len(skill_content) > 500 else skill_content
            })
        except Exception as e:
            safe_print(f"[WARN] Failed to parse skill {skill_dir.name}: {e}")

    return {
        "skills": skills,
        "skills_dir": str(SKILLS_DIR),
        "count": len(skills)
    }


@app.get("/api/skills/{skill_id}")
async def get_skill(skill_id: str):
    """è·å–æŒ‡å®š Skill çš„è¯¦ç»†ä¿¡æ¯"""
    skill_file = SKILLS_DIR / skill_id / "SKILL.md"

    if not skill_file.exists():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")

    with open(skill_file, "r", encoding="utf-8") as f:
        content = f.read()

    metadata = parse_skill_metadata(content)

    # æå–å®Œæ•´å†…å®¹
    content_start = content.find("---", 3)
    if content_start != -1:
        skill_content = content[content_start + 3:].strip()
    else:
        skill_content = content

    return {
        "id": skill_id,
        "name": metadata.get("name", skill_id),
        "description": metadata.get("description", ""),
        "allowed_tools": metadata.get("allowed-tools", "").split(", ") if metadata.get("allowed-tools") else [],
        "file_path": str(skill_file),
        "content": skill_content,
        "raw": content
    }


# === WebSearch æ›¿ä»£æ–¹æ¡ˆ (#6) ===
# SDK å†…ç½®çš„ WebSearch åœ¨æŸäº›ç¯å¢ƒä¸‹ä¼šå¤±è´¥ (exit code 1)
# ä½¿ç”¨ SerpAPI ä½œä¸ºæ›¿ä»£æœç´¢åç«¯

import urllib.request
import urllib.parse


def serpapi_search(query: str, max_results: int = 5) -> dict:
    """
    ä½¿ç”¨ SerpAPI è¿›è¡Œç½‘ç»œæœç´¢

    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°

    Returns:
        æœç´¢ç»“æœå­—å…¸
    """
    try:
        # ä»ç¯å¢ƒå˜é‡è¯»å– API Key
        serpapi_key = os.environ.get("SERPAPI_API_KEY", "")
        if not serpapi_key:
            return {"error": "SERPAPI_API_KEY æœªé…ç½®", "results": []}

        encoded_query = urllib.parse.quote(query)
        url = f"https://serpapi.com/search.json?q={encoded_query}&api_key={serpapi_key}&num={max_results}"

        req = urllib.request.Request(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

        with urllib.request.urlopen(req, timeout=15) as response:
            data = json.loads(response.read().decode("utf-8"))

        results = []
        organic_results = data.get("organic_results", [])

        for i, item in enumerate(organic_results[:max_results]):
            results.append({
                "position": i + 1,
                "title": item.get("title", "æ— æ ‡é¢˜"),
                "link": item.get("link", ""),
                "snippet": item.get("snippet", "")[:200],
                "displayed_link": item.get("displayed_link", "")
            })

        return {
            "success": True,
            "query": query,
            "results": results,
            "total_results": len(results)
        }

    except urllib.error.URLError as e:
        return {
            "success": False,
            "query": query,
            "error": f"ç½‘ç»œé”™è¯¯: {str(e)}",
            "results": []
        }
    except Exception as e:
        return {
            "success": False,
            "query": query,
            "error": f"æœç´¢å‡ºé”™: {str(e)}",
            "results": []
        }


class SearchRequest:
    """æœç´¢è¯·æ±‚æ¨¡å‹"""
    pass


from pydantic import BaseModel


class SearchRequestModel(BaseModel):
    query: str
    max_results: int = 5


@app.post("/api/search")
async def web_search(request: SearchRequestModel):
    """
    ç½‘ç»œæœç´¢ API (#6)

    å½“ SDK å†…ç½®çš„ WebSearch å·¥å…·å¤±è´¥æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ­¤ç«¯ç‚¹ä½œä¸ºæ›¿ä»£ã€‚
    ä½¿ç”¨ SerpAPI ä½œä¸ºæœç´¢åç«¯ã€‚

    Request body:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•° (é»˜è®¤ 5)

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    safe_print(f"[SEARCH] æœç´¢è¯·æ±‚: {request.query}")
    result = serpapi_search(request.query, request.max_results)

    if result["success"]:
        safe_print(f"[SEARCH] æ‰¾åˆ° {result['total_results']} æ¡ç»“æœ")
    else:
        safe_print(f"[SEARCH] æœç´¢å¤±è´¥: {result.get('error', 'Unknown error')}")

    return result


@app.get("/api/search")
async def web_search_get(query: str, max_results: int = 5):
    """
    ç½‘ç»œæœç´¢ API (GET æ–¹æ³•)

    æ–¹ä¾¿åœ¨æµè§ˆå™¨ä¸­ç›´æ¥æµ‹è¯•ã€‚
    """
    return serpapi_search(query, max_results)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
